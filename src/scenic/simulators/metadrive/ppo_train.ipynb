{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931f5618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kxu/ScenicGym/src/scenic/core/errors.py:271: UserWarning: unable to install sys.excepthook to format Scenic backtraces\n",
      "  warnings.warn(\"unable to install sys.excepthook to format Scenic backtraces\")\n"
     ]
    }
   ],
   "source": [
    "from scenic.zoo import ScenicZooEnv\n",
    "from scenic.simulators.metadrive import MetaDriveSimulator\n",
    "import scenic\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.ppo import MlpPolicy\n",
    "# from stable_baselines3.common.monitor import Monitor\n",
    "# from stable_baselines3.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# from stable_baselines3.common.utils import set_random_seed\n",
    "# import supersuit as ss\n",
    "import os\n",
    "\n",
    "\n",
    "# %%\n",
    "import contextlib\n",
    "import logging\n",
    "import pathlib\n",
    "import time\n",
    "# from collections import deque\n",
    "# from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import tyro\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14aee22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_user = os.path.expanduser(\"~\")\n",
    "root_user\n",
    "\n",
    "with contextlib.suppress(RuntimeError):\n",
    "        mp.set_start_method(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca76cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumo_map = root_user + \"/ScenicGym/assets/maps/CARLA/Town04.net.xml\"\n",
    "obs_space_dict = {\"agent0\" :  gym.spaces.Box(-0.0, 1.0 , (249,), dtype=np.float32),\n",
    "                 \"agent1\": gym.spaces.Box(-0.0, 1.0 , (249,), dtype=np.float32)}\n",
    "\n",
    "action_space_dict = {'agent0': gym.spaces.Box(-1.0, 1.0, (2,), np.float32),\n",
    "                     'agent1': gym.spaces.Box(-1.0, 1.0, (2,), np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0ff89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = scenic.scenarioFromFile(\"exp.scenic\",\n",
    "                               model=\"scenic.simulators.metadrive.model\",\n",
    "                           mode2D=True)\n",
    "env = ScenicZooEnv(scenario, \n",
    "                       MetaDriveSimulator(sumo_map=sumo_map, render=False, real_time=False),\n",
    "                       None, \n",
    "                       max_steps=100, \n",
    "                       observation_space = obs_space_dict, \n",
    "                       action_space = action_space_dict, \n",
    "                       agents=[\"agent0\", \"agent1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95df56f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIM START\n",
      "Epoch Number: 0\n",
      "STEP: 0\n",
      "DETERMINED ACTION: {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "step reward {'agent0': 0.0, 'agent1': 0.0}\n",
      "STEP: 1\n",
      "DETERMINED ACTION: {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "ACTION = {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "step reward {'agent0': 0.0038526555422579946, 'agent1': 0.004135040017045982}\n",
      "STEP: 2\n",
      "DETERMINED ACTION: {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "step reward {'agent0': 0.01736952331648215, 'agent1': 0.01858249846210685}\n",
      "STEP: 3\n",
      "DETERMINED ACTION: {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "step reward {'agent0': 0.031146377108932685, 'agent1': 0.03326491356415968}\n",
      "STEP: 4\n",
      "DETERMINED ACTION: {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "ACTION = {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "step reward {'agent0': 0.04440653490555097, 'agent1': 0.04752700047206012}\n",
      "STEP: 5\n",
      "DETERMINED ACTION: {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "ACTION = {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "step reward {'agent0': 0.05722315501278951, 'agent1': 0.061258810639572725}\n",
      "STEP: 6\n",
      "DETERMINED ACTION: {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "step reward {'agent0': 0.0697701561301046, 'agent1': 0.07460161797301573}\n",
      "STEP: 7\n",
      "DETERMINED ACTION: {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "ACTION = {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "step reward {'agent0': 0.08185168189329399, 'agent1': 0.08754333648014992}\n",
      "STEP: 8\n",
      "DETERMINED ACTION: {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "ACTION = {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "step reward {'agent0': 0.09352529335224245, 'agent1': 0.10008022845947041}\n",
      "STEP: 9\n",
      "DETERMINED ACTION: {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "step reward {'agent0': 0.10481378900734901, 'agent1': 0.11217525188540045}\n",
      "STEP: 10\n",
      "DETERMINED ACTION: {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1157129144535832, 'agent1': 0.12385333999079096}\n",
      "STEP: 11\n",
      "DETERMINED ACTION: {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "ACTION = {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "step reward {'agent0': 0.1262213475412153, 'agent1': 0.13511436783483488}\n",
      "STEP: 12\n",
      "DETERMINED ACTION: {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "ACTION = {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "step reward {'agent0': 0.13634121315703499, 'agent1': 0.14595952800487072}\n",
      "STEP: 13\n",
      "DETERMINED ACTION: {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1460735712330344, 'agent1': 0.1563289763156302}\n",
      "STEP: 14\n",
      "DETERMINED ACTION: {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "ACTION = {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "step reward {'agent0': 0.15541868313394386, 'agent1': 0.1662849479755415}\n",
      "STEP: 15\n",
      "DETERMINED ACTION: {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "ACTION = {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "step reward {'agent0': 0.16437708022658917, 'agent1': 0.17579624822253034}\n",
      "STEP: 16\n",
      "DETERMINED ACTION: {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "ACTION = {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "step reward {'agent0': 0.172825888977618, 'agent1': 0.18492378080641061}\n",
      "STEP: 17\n",
      "DETERMINED ACTION: {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "step reward {'agent0': 0.18094927867844784, 'agent1': 0.1934862957290193}\n",
      "STEP: 18\n",
      "DETERMINED ACTION: {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "ACTION = {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "step reward {'agent0': 0.18862464349410019, 'agent1': 0.20178683347265308}\n",
      "STEP: 19\n",
      "DETERMINED ACTION: {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "ACTION = {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "step reward {'agent0': 0.19585277335928464, 'agent1': 0.20952260727064792}\n",
      "STEP: 20\n",
      "DETERMINED ACTION: {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20266391293275338, 'agent1': 0.21669282033876464}\n",
      "STEP: 21\n",
      "DETERMINED ACTION: {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20905913197290127, 'agent1': 0.2235422691307034}\n",
      "STEP: 22\n",
      "DETERMINED ACTION: {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "ACTION = {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "step reward {'agent0': 0.21500709893949915, 'agent1': 0.2298567959083872}\n",
      "STEP: 23\n",
      "DETERMINED ACTION: {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "ACTION = {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "step reward {'agent0': 0.22047862820241032, 'agent1': 0.23569848587628495}\n",
      "STEP: 24\n",
      "DETERMINED ACTION: {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "step reward {'agent0': 0.22556473521857456, 'agent1': 0.24106853961641284}\n",
      "STEP: 25\n",
      "DETERMINED ACTION: {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "ACTION = {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "step reward {'agent0': 0.2301741291411029, 'agent1': 0.24590457763296747}\n",
      "STEP: 26\n",
      "DETERMINED ACTION: {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "ACTION = {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "step reward {'agent0': 0.23427707819948046, 'agent1': 0.2502379111658073}\n",
      "STEP: 27\n",
      "DETERMINED ACTION: {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2379346168747179, 'agent1': 0.254069596237227}\n",
      "STEP: 28\n",
      "DETERMINED ACTION: {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24111621721929616, 'agent1': 0.25733713266445635}\n",
      "STEP: 29\n",
      "DETERMINED ACTION: {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "ACTION = {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "step reward {'agent0': 0.24373085892856883, 'agent1': 0.26004223610238325}\n",
      "STEP: 30\n",
      "DETERMINED ACTION: {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "ACTION = {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "step reward {'agent0': 0.24590086807487066, 'agent1': 0.26221608247272005}\n",
      "STEP: 31\n",
      "DETERMINED ACTION: {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2475352144369064, 'agent1': 0.26379682596068005}\n",
      "STEP: 32\n",
      "DETERMINED ACTION: {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "ACTION = {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "step reward {'agent0': 0.24860337945049588, 'agent1': 0.26484655637077226}\n",
      "STEP: 33\n",
      "DETERMINED ACTION: {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "ACTION = {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "step reward {'agent0': 0.24913559949062025, 'agent1': 0.2651831057182559}\n",
      "STEP: 34\n",
      "DETERMINED ACTION: {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2491024206288558, 'agent1': 0.26492785921826817}\n",
      "STEP: 35\n",
      "DETERMINED ACTION: {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24850409257288109, 'agent1': 0.26402030454888425}\n",
      "STEP: 36\n",
      "DETERMINED ACTION: {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "ACTION = {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "step reward {'agent0': 0.24727958048560833, 'agent1': 0.2624605548971004}\n",
      "STEP: 37\n",
      "DETERMINED ACTION: {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "ACTION = {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "step reward {'agent0': 0.24545992182444798, 'agent1': 0.26018904304213286}\n",
      "STEP: 38\n",
      "DETERMINED ACTION: {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24304512040524628, 'agent1': 0.257204424524462}\n",
      "STEP: 39\n",
      "DETERMINED ACTION: {'agent0': [0.10039000000000001, 0.5], 'agent1': [0.10039000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10039000000000001, 0.5], 'agent1': [0.10039000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2398831022812552, 'agent1': 0.25350828741452336}\n",
      "STEP: 40\n",
      "DETERMINED ACTION: {'agent0': [0.1004, 0.5], 'agent1': [0.1004, 0.5]}\n",
      "ACTION = {'agent0': [0.1004, 0.5], 'agent1': [0.1004, 0.5]}\n",
      "step reward {'agent0': 0.2361269704705572, 'agent1': 0.24900919970129443}\n",
      "STEP: 41\n",
      "DETERMINED ACTION: {'agent0': [0.10041, 0.5], 'agent1': [0.10041, 0.5]}\n",
      "ACTION = {'agent0': [0.10041, 0.5], 'agent1': [0.10041, 0.5]}\n",
      "step reward {'agent0': 0.23168517448967663, 'agent1': 0.24379910038705377}\n",
      "STEP: 42\n",
      "DETERMINED ACTION: {'agent0': [0.10042000000000001, 0.5], 'agent1': [0.10042000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10042000000000001, 0.5], 'agent1': [0.10042000000000001, 0.5]}\n",
      "step reward {'agent0': 0.22649719879575614, 'agent1': 0.23769474630070475}\n",
      "STEP: 43\n",
      "DETERMINED ACTION: {'agent0': [0.10043, 0.5], 'agent1': [0.10043, 0.5]}\n",
      "ACTION = {'agent0': [0.10043, 0.5], 'agent1': [0.10043, 0.5]}\n",
      "step reward {'agent0': 0.2205630330327143, 'agent1': 0.23084976551065894}\n",
      "STEP: 44\n",
      "DETERMINED ACTION: {'agent0': [0.10044, 0.5], 'agent1': [0.10044, 0.5]}\n",
      "ACTION = {'agent0': [0.10044, 0.5], 'agent1': [0.10044, 0.5]}\n",
      "step reward {'agent0': 0.21388346304727712, 'agent1': 0.22308091837462174}\n",
      "STEP: 45\n",
      "DETERMINED ACTION: {'agent0': [0.10045000000000001, 0.5], 'agent1': [0.10045000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10045000000000001, 0.5], 'agent1': [0.10045000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20639745008840882, 'agent1': 0.21438924882508525}\n",
      "STEP: 46\n",
      "DETERMINED ACTION: {'agent0': [0.10046000000000001, 0.5], 'agent1': [0.10046000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10046000000000001, 0.5], 'agent1': [0.10046000000000001, 0.5]}\n",
      "step reward {'agent0': 0.19810524139039576, 'agent1': 0.20480553415904001}\n",
      "STEP: 47\n",
      "DETERMINED ACTION: {'agent0': [0.10047, 0.5], 'agent1': [0.10047, 0.5]}\n",
      "ACTION = {'agent0': [0.10047, 0.5], 'agent1': [0.10047, 0.5]}\n",
      "step reward {'agent0': 0.18897711397151717, 'agent1': 0.1942380710810503}\n",
      "STEP: 48\n",
      "DETERMINED ACTION: {'agent0': [0.10048, 0.5], 'agent1': [0.10048, 0.5]}\n",
      "ACTION = {'agent0': [0.10048, 0.5], 'agent1': [0.10048, 0.5]}\n",
      "step reward {'agent0': 0.17898253772884165, 'agent1': 0.18271869605652702}\n",
      "STEP: 49\n",
      "DETERMINED ACTION: {'agent0': [0.10049000000000001, 0.5], 'agent1': [0.10049000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10049000000000001, 0.5], 'agent1': [0.10049000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1680917865311754, 'agent1': 0.17018609640814342}\n",
      "STEP: 50\n",
      "DETERMINED ACTION: {'agent0': [0.1005, 0.5], 'agent1': [0.1005, 0.5]}\n",
      "ACTION = {'agent0': [0.1005, 0.5], 'agent1': [0.1005, 0.5]}\n",
      "step reward {'agent0': 0.15630431166243253, 'agent1': 0.15654924371791923}\n",
      "STEP: 51\n",
      "DETERMINED ACTION: {'agent0': [0.10051, 0.5], 'agent1': [0.10051, 0.5]}\n",
      "ACTION = {'agent0': [0.10051, 0.5], 'agent1': [0.10051, 0.5]}\n",
      "step reward {'agent0': 0.14356066328962858, 'agent1': 0.14177806359097478}\n",
      "STEP: 52\n",
      "DETERMINED ACTION: {'agent0': [0.10052000000000001, 0.5], 'agent1': [0.10052000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10052000000000001, 0.5], 'agent1': [0.10052000000000001, 0.5]}\n",
      "step reward {'agent0': 0.12979899340145007, 'agent1': 0.1259646395770696}\n",
      "STEP: 53\n",
      "DETERMINED ACTION: {'agent0': [0.10053000000000001, 0.5], 'agent1': [0.10053000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10053000000000001, 0.5], 'agent1': [0.10053000000000001, 0.5]}\n",
      "step reward {'agent0': 0.11505115327016069, 'agent1': 0.10889531748837311}\n",
      "STEP: 54\n",
      "DETERMINED ACTION: {'agent0': [0.10054, 0.5], 'agent1': [0.10054, 0.5]}\n",
      "ACTION = {'agent0': [0.10054, 0.5], 'agent1': [0.10054, 0.5]}\n",
      "step reward {'agent0': 0.09925635212779294, 'agent1': 0.0907243503795282}\n",
      "STEP: 55\n",
      "DETERMINED ACTION: {'agent0': [0.10055, 0.5], 'agent1': [0.10055, 0.5]}\n",
      "ACTION = {'agent0': [0.10055, 0.5], 'agent1': [0.10055, 0.5]}\n",
      "step reward {'agent0': 0.08241431225594753, 'agent1': 0.07123734876105403}\n",
      "STEP: 56\n",
      "DETERMINED ACTION: {'agent0': [0.10056000000000001, 0.5], 'agent1': [0.10056000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10056000000000001, 0.5], 'agent1': [0.10056000000000001, 0.5]}\n",
      "step reward {'agent0': 0.06443451709623038, 'agent1': 0.050465959777381775}\n",
      "STEP: 57\n",
      "DETERMINED ACTION: {'agent0': [0.10057, 0.5], 'agent1': [0.10057, 0.5]}\n",
      "ACTION = {'agent0': [0.10057, 0.5], 'agent1': [0.10057, 0.5]}\n",
      "step reward {'agent0': 0.045286723943816165, 'agent1': 0.028471611095679195}\n",
      "STEP: 58\n",
      "DETERMINED ACTION: {'agent0': [0.10058, 0.5], 'agent1': [0.10058, 0.5]}\n",
      "ACTION = {'agent0': [0.10058, 0.5], 'agent1': [0.10058, 0.5]}\n",
      "step reward {'agent0': 0.02500143643323738, 'agent1': 0.0050413143016242445}\n",
      "STEP: 59\n",
      "DETERMINED ACTION: {'agent0': [0.10059, 0.5], 'agent1': [0.10059, 0.5]}\n",
      "ACTION = {'agent0': [0.10059, 0.5], 'agent1': [0.10059, 0.5]}\n",
      "step reward {'agent0': 0.003457640124702732, 'agent1': -0.0197635750501437}\n",
      "STEP: 60\n",
      "DETERMINED ACTION: {'agent0': [0.10060000000000001, 0.5], 'agent1': [0.10060000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10060000000000001, 0.5], 'agent1': [0.10060000000000001, 0.5]}\n",
      "step reward {'agent0': -0.019283648609042192, 'agent1': -0.04600350169472878}\n",
      "STEP: 61\n",
      "DETERMINED ACTION: {'agent0': [0.10061, 0.5], 'agent1': [0.10061, 0.5]}\n",
      "ACTION = {'agent0': [0.10061, 0.5], 'agent1': [0.10061, 0.5]}\n",
      "step reward {'agent0': -0.043312938962758674, 'agent1': -0.07370819804677142}\n",
      "STEP: 62\n",
      "DETERMINED ACTION: {'agent0': [0.10062, 0.5], 'agent1': [0.10062, 0.5]}\n",
      "ACTION = {'agent0': [0.10062, 0.5], 'agent1': [0.10062, 0.5]}\n",
      "step reward {'agent0': -0.06866101799615221, 'agent1': -0.10296924159598164}\n",
      "STEP: 63\n",
      "DETERMINED ACTION: {'agent0': [0.10063000000000001, 0.5], 'agent1': [0.10063000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10063000000000001, 0.5], 'agent1': [0.10063000000000001, 0.5]}\n",
      "step reward {'agent0': -0.09538813531196022, 'agent1': -0.133785785713179}\n",
      "STEP: 64\n",
      "DETERMINED ACTION: {'agent0': [0.10064000000000001, 0.5], 'agent1': [0.10064000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10064000000000001, 0.5], 'agent1': [0.10064000000000001, 0.5]}\n",
      "step reward {'agent0': -0.12343274689816996, 'agent1': -0.1661577848537158}\n",
      "STEP: 65\n",
      "DETERMINED ACTION: {'agent0': [0.10065, 0.5], 'agent1': [0.10065, 0.5]}\n",
      "ACTION = {'agent0': [0.10065, 0.5], 'agent1': [0.10065, 0.5]}\n",
      "step reward {'agent0': -0.15293166096010968, 'agent1': -0.20017559610980518}\n",
      "STEP: 66\n",
      "DETERMINED ACTION: {'agent0': [0.10066, 0.5], 'agent1': [0.10066, 0.5]}\n",
      "ACTION = {'agent0': [0.10066, 0.5], 'agent1': [0.10066, 0.5]}\n",
      "step reward {'agent0': -0.1838693598592016, 'agent1': -0.2357778696170314}\n",
      "STEP: 67\n",
      "DETERMINED ACTION: {'agent0': [0.10067000000000001, 0.5], 'agent1': [0.10067000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10067000000000001, 0.5], 'agent1': [0.10067000000000001, 0.5]}\n",
      "step reward {'agent0': -0.21627584764259888, 'agent1': -0.2731773986296212}\n",
      "STEP: 68\n",
      "DETERMINED ACTION: {'agent0': [0.10068, 0.5], 'agent1': [0.10068, 0.5]}\n",
      "ACTION = {'agent0': [0.10068, 0.5], 'agent1': [0.10068, 0.5]}\n",
      "step reward {'agent0': -0.25022689964158606, 'agent1': -0.3122822827984343}\n",
      "STEP: 69\n",
      "DETERMINED ACTION: {'agent0': [0.10069, 0.5], 'agent1': [0.10069, 0.5]}\n",
      "ACTION = {'agent0': [0.10069, 0.5], 'agent1': [0.10069, 0.5]}\n",
      "step reward {'agent0': -0.28569120877809673, 'agent1': -0.35315326936953517}\n",
      "STEP: 70\n",
      "DETERMINED ACTION: {'agent0': [0.10070000000000001, 0.5], 'agent1': [0.10070000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10070000000000001, 0.5], 'agent1': [0.10070000000000001, 0.5]}\n",
      "step reward {'agent0': -0.3227450927483254, 'agent1': -0.3958202284220428}\n",
      "STEP: 71\n",
      "DETERMINED ACTION: {'agent0': [0.10071000000000001, 0.5], 'agent1': [0.10071000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10071000000000001, 0.5], 'agent1': [0.10071000000000001, 0.5]}\n",
      "step reward {'agent0': -0.36140275289725854, 'agent1': -0.44034326283786196}\n",
      "STEP: 72\n",
      "DETERMINED ACTION: {'agent0': [0.10072, 0.5], 'agent1': [0.10072, 0.5]}\n",
      "ACTION = {'agent0': [0.10072, 0.5], 'agent1': [0.10072, 0.5]}\n",
      "step reward {'agent0': -0.401694878118788, 'agent1': -0.4866913677045185}\n",
      "STEP: 73\n",
      "DETERMINED ACTION: {'agent0': [0.10073, 0.5], 'agent1': [0.10073, 0.5]}\n",
      "ACTION = {'agent0': [0.10073, 0.5], 'agent1': [0.10073, 0.5]}\n",
      "step reward {'agent0': -0.44366601738603684, 'agent1': -0.5349245552051671}\n",
      "STEP: 74\n",
      "DETERMINED ACTION: {'agent0': [0.10074000000000001, 0.5], 'agent1': [0.10074000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10074000000000001, 0.5], 'agent1': [0.10074000000000001, 0.5]}\n",
      "step reward {'agent0': -0.48730082923525564, 'agent1': -0.5851341895006041}\n",
      "STEP: 75\n",
      "DETERMINED ACTION: {'agent0': [0.10075, 0.5], 'agent1': [0.10075, 0.5]}\n",
      "ACTION = {'agent0': [0.10075, 0.5], 'agent1': [0.10075, 0.5]}\n",
      "step reward {'agent0': -0.5326742840891793, 'agent1': -0.6371974932890516}\n",
      "STEP: 76\n",
      "DETERMINED ACTION: {'agent0': [0.10076, 0.5], 'agent1': [0.10076, 0.5]}\n",
      "ACTION = {'agent0': [0.10076, 0.5], 'agent1': [0.10076, 0.5]}\n",
      "step reward {'agent0': -0.5797574595236962, 'agent1': -0.6912969799592563}\n",
      "STEP: 77\n",
      "DETERMINED ACTION: {'agent0': [0.10077000000000001, 0.5], 'agent1': [0.10077000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10077000000000001, 0.5], 'agent1': [0.10077000000000001, 0.5]}\n",
      "step reward {'agent0': -0.628594444379631, 'agent1': -0.7473095698762369}\n",
      "STEP: 78\n",
      "DETERMINED ACTION: {'agent0': [0.10078000000000001, 0.5], 'agent1': [0.10078000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10078000000000001, 0.5], 'agent1': [0.10078000000000001, 0.5]}\n",
      "step reward {'agent0': -0.6792281003894224, 'agent1': -0.8052958279996254}\n",
      "STEP: 79\n",
      "DETERMINED ACTION: {'agent0': [0.10079, 0.5], 'agent1': [0.10079, 0.5]}\n",
      "ACTION = {'agent0': [0.10079, 0.5], 'agent1': [0.10079, 0.5]}\n",
      "step reward {'agent0': -0.7316456957651727, 'agent1': -0.8652857111026409}\n",
      "STEP: 80\n",
      "DETERMINED ACTION: {'agent0': [0.1008, 0.5], 'agent1': [0.1008, 0.5]}\n",
      "ACTION = {'agent0': [0.1008, 0.5], 'agent1': [0.1008, 0.5]}\n",
      "step reward {'agent0': -0.7858607745036724, 'agent1': -0.9273088319480154}\n",
      "STEP: 81\n",
      "DETERMINED ACTION: {'agent0': [0.10081000000000001, 0.5], 'agent1': [0.10081000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10081000000000001, 0.5], 'agent1': [0.10081000000000001, 0.5]}\n",
      "step reward {'agent0': -0.8418730992969974, 'agent1': -0.9912731161866577}\n",
      "STEP: 82\n",
      "DETERMINED ACTION: {'agent0': [0.10082, 0.5], 'agent1': [0.10082, 0.5]}\n",
      "ACTION = {'agent0': [0.10082, 0.5], 'agent1': [0.10082, 0.5]}\n",
      "step reward {'agent0': -0.8996966298454178, 'agent1': -1.0572999285842544}\n",
      "STEP: 83\n",
      "DETERMINED ACTION: {'agent0': [0.10083, 0.5], 'agent1': [0.10083, 0.5]}\n",
      "ACTION = {'agent0': [0.10083, 0.5], 'agent1': [0.10083, 0.5]}\n",
      "step reward {'agent0': -0.9593614469889395, 'agent1': -1.1252662404826483}\n",
      "STEP: 84\n",
      "DETERMINED ACTION: {'agent0': [0.10084, 0.5], 'agent1': [0.10084, 0.5]}\n",
      "ACTION = {'agent0': [0.10084, 0.5], 'agent1': [0.10084, 0.5]}\n",
      "step reward {'agent0': -1.020852227144615, 'agent1': -1.195171561759842}\n",
      "STEP: 85\n",
      "DETERMINED ACTION: {'agent0': [0.10085000000000001, 0.5], 'agent1': [0.10085000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10085000000000001, 0.5], 'agent1': [0.10085000000000001, 0.5]}\n",
      "step reward {'agent0': -1.0841683079302036, 'agent1': -1.2671370957023391}\n",
      "STEP: 86\n",
      "DETERMINED ACTION: {'agent0': [0.10086, 0.5], 'agent1': [0.10086, 0.5]}\n",
      "ACTION = {'agent0': [0.10086, 0.5], 'agent1': [0.10086, 0.5]}\n",
      "step reward {'agent0': -1.1492775775647215, 'agent1': -1.341040154235752}\n",
      "STEP: 87\n",
      "DETERMINED ACTION: {'agent0': [0.10087, 0.5], 'agent1': [0.10087, 0.5]}\n",
      "ACTION = {'agent0': [0.10087, 0.5], 'agent1': [0.10087, 0.5]}\n",
      "step reward {'agent0': -1.2162246465348785, 'agent1': -1.4167576813382585}\n",
      "STEP: 88\n",
      "DETERMINED ACTION: {'agent0': [0.10088000000000001, 0.5], 'agent1': [0.10088000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10088000000000001, 0.5], 'agent1': [0.10088000000000001, 0.5]}\n",
      "step reward {'agent0': -1.2849040276265027, 'agent1': -1.4944415972682155}\n",
      "STEP: 89\n",
      "DETERMINED ACTION: {'agent0': [0.10089000000000001, 0.5], 'agent1': [0.10089000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10089000000000001, 0.5], 'agent1': [0.10089000000000001, 0.5]}\n",
      "step reward {'agent0': -1.3553907264405394, 'agent1': -4.669542424464415}\n",
      "STEP: 90\n",
      "DETERMINED ACTION: {'agent0': [0.1009, 0.5], 'agent1': [0.1009, 0.5]}\n",
      "ACTION = {'agent0': [0.1009, 0.5], 'agent1': [0.1009, 0.5]}\n",
      "step reward {'agent0': -1.4276224071837524, 'agent1': -4.6795321182860325}\n",
      "STEP: 91\n",
      "DETERMINED ACTION: {'agent0': [0.10091, 0.5], 'agent1': [0.10091, 0.5]}\n",
      "ACTION = {'agent0': [0.10091, 0.5], 'agent1': [0.10091, 0.5]}\n",
      "step reward {'agent0': -1.5015536756472752, 'agent1': -4.6904590524539485}\n",
      "STEP: 92\n",
      "DETERMINED ACTION: {'agent0': [0.10092000000000001, 0.5], 'agent1': [0.10092000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10092000000000001, 0.5], 'agent1': [0.10092000000000001, 0.5]}\n",
      "step reward {'agent0': -1.577167562839294, 'agent1': -4.702354745554969}\n",
      "STEP: 93\n",
      "DETERMINED ACTION: {'agent0': [0.10093, 0.5], 'agent1': [0.10093, 0.5]}\n",
      "ACTION = {'agent0': [0.10093, 0.5], 'agent1': [0.10093, 0.5]}\n",
      "step reward {'agent0': -1.6544181798295483, 'agent1': -4.7151589294227305}\n",
      "STEP: 94\n",
      "DETERMINED ACTION: {'agent0': [0.10094, 0.5], 'agent1': [0.10094, 0.5]}\n",
      "ACTION = {'agent0': [0.10094, 0.5], 'agent1': [0.10094, 0.5]}\n",
      "step reward {'agent0': -1.7332739758691338, 'agent1': -4.728720054093723}\n",
      "STEP: 95\n",
      "DETERMINED ACTION: {'agent0': [0.10095000000000001, 0.5], 'agent1': [0.10095000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10095000000000001, 0.5], 'agent1': [0.10095000000000001, 0.5]}\n",
      "step reward {'agent0': -1.8136733776465979, 'agent1': -4.743099989101647}\n",
      "STEP: 96\n",
      "DETERMINED ACTION: {'agent0': [0.10096000000000001, 0.5], 'agent1': [0.10096000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10096000000000001, 0.5], 'agent1': [0.10096000000000001, 0.5]}\n",
      "step reward {'agent0': -1.8956007634156586, 'agent1': -4.758055401168853}\n",
      "STEP: 97\n",
      "DETERMINED ACTION: {'agent0': [0.10097, 0.5], 'agent1': [0.10097, 0.5]}\n",
      "ACTION = {'agent0': [0.10097, 0.5], 'agent1': [0.10097, 0.5]}\n",
      "step reward {'agent0': -1.978932474635172, 'agent1': -4.773587320420233}\n",
      "STEP: 98\n",
      "DETERMINED ACTION: {'agent0': [0.10098, 0.5], 'agent1': [0.10098, 0.5]}\n",
      "ACTION = {'agent0': [0.10098, 0.5], 'agent1': [0.10098, 0.5]}\n",
      "step reward {'agent0': -2.0636072536251016, 'agent1': -4.789604962613751}\n",
      "STEP: 99\n",
      "DETERMINED ACTION: {'agent0': [0.10099000000000001, 0.5], 'agent1': [0.10099000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10099000000000001, 0.5], 'agent1': [0.10099000000000001, 0.5]}\n",
      "step reward {'agent0': -2.149608894522588, 'agent1': -4.8060481856717185}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 1\n",
      "STEP: 0\n",
      "DETERMINED ACTION: {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "step reward {'agent0': 0.0, 'agent1': 0.0}\n",
      "STEP: 1\n",
      "DETERMINED ACTION: {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "ACTION = {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "step reward {'agent0': 0.0038526555422579946, 'agent1': 0.004135040017045982}\n",
      "STEP: 2\n",
      "DETERMINED ACTION: {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "step reward {'agent0': 0.01736952331648215, 'agent1': 0.01858249846210685}\n",
      "STEP: 3\n",
      "DETERMINED ACTION: {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "step reward {'agent0': 0.031146377108932685, 'agent1': 0.03326491356415968}\n",
      "STEP: 4\n",
      "DETERMINED ACTION: {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "ACTION = {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "step reward {'agent0': 0.04440653490555097, 'agent1': 0.04752700047206012}\n",
      "STEP: 5\n",
      "DETERMINED ACTION: {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "ACTION = {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "step reward {'agent0': 0.05722315501278951, 'agent1': 0.061258810639572725}\n",
      "STEP: 6\n",
      "DETERMINED ACTION: {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "step reward {'agent0': 0.0697701561301046, 'agent1': 0.07460161797301573}\n",
      "STEP: 7\n",
      "DETERMINED ACTION: {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "ACTION = {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "step reward {'agent0': 0.08185168189329399, 'agent1': 0.08754333648014992}\n",
      "STEP: 8\n",
      "DETERMINED ACTION: {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "ACTION = {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "step reward {'agent0': 0.09352529335224245, 'agent1': 0.10008022845947041}\n",
      "STEP: 9\n",
      "DETERMINED ACTION: {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "step reward {'agent0': 0.10481378900734901, 'agent1': 0.11217525188540045}\n",
      "STEP: 10\n",
      "DETERMINED ACTION: {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1157129144535832, 'agent1': 0.12385333999079096}\n",
      "STEP: 11\n",
      "DETERMINED ACTION: {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "ACTION = {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "step reward {'agent0': 0.1262213475412153, 'agent1': 0.13511436783483488}\n",
      "STEP: 12\n",
      "DETERMINED ACTION: {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "ACTION = {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "step reward {'agent0': 0.13634121315703499, 'agent1': 0.14595952800487072}\n",
      "STEP: 13\n",
      "DETERMINED ACTION: {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1460735712330344, 'agent1': 0.1563289763156302}\n",
      "STEP: 14\n",
      "DETERMINED ACTION: {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "ACTION = {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "step reward {'agent0': 0.15541868313394386, 'agent1': 0.1662849479755415}\n",
      "STEP: 15\n",
      "DETERMINED ACTION: {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "ACTION = {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "step reward {'agent0': 0.16437708022658917, 'agent1': 0.17579624822253034}\n",
      "STEP: 16\n",
      "DETERMINED ACTION: {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "ACTION = {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "step reward {'agent0': 0.172825888977618, 'agent1': 0.18492378080641061}\n",
      "STEP: 17\n",
      "DETERMINED ACTION: {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "step reward {'agent0': 0.18094927867844784, 'agent1': 0.1934862957290193}\n",
      "STEP: 18\n",
      "DETERMINED ACTION: {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "ACTION = {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "step reward {'agent0': 0.18862464349410019, 'agent1': 0.20178683347265308}\n",
      "STEP: 19\n",
      "DETERMINED ACTION: {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "ACTION = {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "step reward {'agent0': 0.19585277335928464, 'agent1': 0.20952260727064792}\n",
      "STEP: 20\n",
      "DETERMINED ACTION: {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20266391293275338, 'agent1': 0.21669282033876464}\n",
      "STEP: 21\n",
      "DETERMINED ACTION: {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20905913197290127, 'agent1': 0.2235422691307034}\n",
      "STEP: 22\n",
      "DETERMINED ACTION: {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "ACTION = {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "step reward {'agent0': 0.21500709893949915, 'agent1': 0.2298567959083872}\n",
      "STEP: 23\n",
      "DETERMINED ACTION: {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "ACTION = {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "step reward {'agent0': 0.22047862820241032, 'agent1': 0.23569848587628495}\n",
      "STEP: 24\n",
      "DETERMINED ACTION: {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "step reward {'agent0': 0.22556473521857456, 'agent1': 0.24106853961641284}\n",
      "STEP: 25\n",
      "DETERMINED ACTION: {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "ACTION = {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "step reward {'agent0': 0.2301741291411029, 'agent1': 0.24590457763296747}\n",
      "STEP: 26\n",
      "DETERMINED ACTION: {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "ACTION = {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "step reward {'agent0': 0.23427707819948046, 'agent1': 0.2502379111658073}\n",
      "STEP: 27\n",
      "DETERMINED ACTION: {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2379346168747179, 'agent1': 0.254069596237227}\n",
      "STEP: 28\n",
      "DETERMINED ACTION: {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24111621721929616, 'agent1': 0.25733713266445635}\n",
      "STEP: 29\n",
      "DETERMINED ACTION: {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "ACTION = {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "step reward {'agent0': 0.24373085892856883, 'agent1': 0.26004223610238325}\n",
      "STEP: 30\n",
      "DETERMINED ACTION: {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "ACTION = {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "step reward {'agent0': 0.24590086807487066, 'agent1': 0.26221608247272005}\n",
      "STEP: 31\n",
      "DETERMINED ACTION: {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2475352144369064, 'agent1': 0.26379682596068005}\n",
      "STEP: 32\n",
      "DETERMINED ACTION: {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "ACTION = {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "step reward {'agent0': 0.24860337945049588, 'agent1': 0.26484655637077226}\n",
      "STEP: 33\n",
      "DETERMINED ACTION: {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "ACTION = {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "step reward {'agent0': 0.24913559949062025, 'agent1': 0.2651831057182559}\n",
      "STEP: 34\n",
      "DETERMINED ACTION: {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2491024206288558, 'agent1': 0.26492785921826817}\n",
      "STEP: 35\n",
      "DETERMINED ACTION: {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24850409257288109, 'agent1': 0.26402030454888425}\n",
      "STEP: 36\n",
      "DETERMINED ACTION: {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "ACTION = {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "step reward {'agent0': 0.24727958048560833, 'agent1': 0.2624605548971004}\n",
      "STEP: 37\n",
      "DETERMINED ACTION: {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "ACTION = {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "step reward {'agent0': -4.774432571432455, 'agent1': -4.784320753942988}\n",
      "STEP: 38\n",
      "DETERMINED ACTION: {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step reward {'agent0': 0, 'agent1': 0}\n",
      "Epoch Number: 2\n",
      "STEP: 0\n",
      "DETERMINED ACTION: {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "step reward {'agent0': 0.0, 'agent1': 0.0}\n",
      "STEP: 1\n",
      "DETERMINED ACTION: {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "ACTION = {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "step reward {'agent0': 0.0038526555422579946, 'agent1': 0.004135040017045982}\n",
      "STEP: 2\n",
      "DETERMINED ACTION: {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "step reward {'agent0': 0.01736952331648215, 'agent1': 0.01858249846210685}\n",
      "STEP: 3\n",
      "DETERMINED ACTION: {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "step reward {'agent0': 0.031146377108932685, 'agent1': 0.03326491356415968}\n",
      "STEP: 4\n",
      "DETERMINED ACTION: {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "ACTION = {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "step reward {'agent0': 0.04440653490555097, 'agent1': 0.04752700047206012}\n",
      "STEP: 5\n",
      "DETERMINED ACTION: {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "ACTION = {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "step reward {'agent0': 0.05722315501278951, 'agent1': 0.061258810639572725}\n",
      "STEP: 6\n",
      "DETERMINED ACTION: {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "step reward {'agent0': 0.0697701561301046, 'agent1': 0.07460161797301573}\n",
      "STEP: 7\n",
      "DETERMINED ACTION: {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "ACTION = {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "step reward {'agent0': 0.08185168189329399, 'agent1': 0.08754333648014992}\n",
      "STEP: 8\n",
      "DETERMINED ACTION: {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "ACTION = {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "step reward {'agent0': 0.09352529335224245, 'agent1': 0.10008022845947041}\n",
      "STEP: 9\n",
      "DETERMINED ACTION: {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "step reward {'agent0': 0.10481378900734901, 'agent1': 0.11217525188540045}\n",
      "STEP: 10\n",
      "DETERMINED ACTION: {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1157129144535832, 'agent1': 0.12385333999079096}\n",
      "STEP: 11\n",
      "DETERMINED ACTION: {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "ACTION = {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "step reward {'agent0': 0.1262213475412153, 'agent1': 0.1351143678223542}\n",
      "STEP: 12\n",
      "DETERMINED ACTION: {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "ACTION = {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "step reward {'agent0': 0.13634121315703499, 'agent1': 0.14595952795359668}\n",
      "STEP: 13\n",
      "DETERMINED ACTION: {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1460735712330344, 'agent1': 0.15632897633477222}\n",
      "STEP: 14\n",
      "DETERMINED ACTION: {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "ACTION = {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "step reward {'agent0': 0.15541868313394386, 'agent1': 0.16628494798068016}\n",
      "STEP: 15\n",
      "DETERMINED ACTION: {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "ACTION = {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "step reward {'agent0': 0.16437708022658917, 'agent1': 0.1757962481618067}\n",
      "STEP: 16\n",
      "DETERMINED ACTION: {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "ACTION = {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "step reward {'agent0': 0.172825888977618, 'agent1': 0.18492377970214993}\n",
      "STEP: 17\n",
      "DETERMINED ACTION: {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "step reward {'agent0': 0.18094927867844784, 'agent1': 0.19348629473739046}\n",
      "STEP: 18\n",
      "DETERMINED ACTION: {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "ACTION = {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "step reward {'agent0': 0.18862464349410019, 'agent1': 0.20178683244633527}\n",
      "STEP: 19\n",
      "DETERMINED ACTION: {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "ACTION = {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "step reward {'agent0': 0.19585277335928464, 'agent1': 0.20952260621882257}\n",
      "STEP: 20\n",
      "DETERMINED ACTION: {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20266391293275338, 'agent1': 0.2166928192575594}\n",
      "STEP: 21\n",
      "DETERMINED ACTION: {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20905913197290127, 'agent1': 0.2235422690971633}\n",
      "STEP: 22\n",
      "DETERMINED ACTION: {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "ACTION = {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "step reward {'agent0': 0.21500709893949915, 'agent1': 0.22985679583673002}\n",
      "STEP: 23\n",
      "DETERMINED ACTION: {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "ACTION = {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "step reward {'agent0': 0.22047862820241032, 'agent1': 0.2356984857998387}\n",
      "STEP: 24\n",
      "DETERMINED ACTION: {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "step reward {'agent0': 0.22556473521857456, 'agent1': 0.2410685385152438}\n",
      "STEP: 25\n",
      "DETERMINED ACTION: {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "ACTION = {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "step reward {'agent0': 0.2301741291411029, 'agent1': 0.24590457670416416}\n",
      "STEP: 26\n",
      "DETERMINED ACTION: {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "ACTION = {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "step reward {'agent0': 0.23427707819948046, 'agent1': 0.25023791006280727}\n",
      "STEP: 27\n",
      "DETERMINED ACTION: {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2379346168747179, 'agent1': 0.25406959513343613}\n",
      "STEP: 28\n",
      "DETERMINED ACTION: {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24111621721929616, 'agent1': 0.2573371326126859}\n",
      "STEP: 29\n",
      "DETERMINED ACTION: {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "ACTION = {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "step reward {'agent0': 0.24373085892856883, 'agent1': 0.26004223610238325}\n",
      "STEP: 30\n",
      "DETERMINED ACTION: {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "ACTION = {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "step reward {'agent0': 0.24590086807487066, 'agent1': 0.26221608247272005}\n",
      "STEP: 31\n",
      "DETERMINED ACTION: {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2475352144369064, 'agent1': 0.26379682596068005}\n",
      "STEP: 32\n",
      "DETERMINED ACTION: {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "ACTION = {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "step reward {'agent0': 0.24860337945049588, 'agent1': 0.2648465561130279}\n",
      "STEP: 33\n",
      "DETERMINED ACTION: {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "ACTION = {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "step reward {'agent0': 0.24913559949062025, 'agent1': 0.2651831059896368}\n",
      "STEP: 34\n",
      "DETERMINED ACTION: {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2491024206288558, 'agent1': 0.264927861714816}\n",
      "STEP: 35\n",
      "DETERMINED ACTION: {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24850409257288109, 'agent1': 0.2640204406284523}\n",
      "STEP: 36\n",
      "DETERMINED ACTION: {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "ACTION = {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "step reward {'agent0': 0.24727958048560833, 'agent1': 0.2624608228000792}\n",
      "STEP: 37\n",
      "DETERMINED ACTION: {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "ACTION = {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "step reward {'agent0': 0.24545992182444798, 'agent1': 0.26018904205330784}\n",
      "STEP: 38\n",
      "DETERMINED ACTION: {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24304512040524628, 'agent1': 0.25720442417942013}\n",
      "STEP: 39\n",
      "DETERMINED ACTION: {'agent0': [0.10039000000000001, 0.5], 'agent1': [0.10039000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10039000000000001, 0.5], 'agent1': [0.10039000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2398831022812552, 'agent1': 0.25350828741452336}\n",
      "STEP: 40\n",
      "DETERMINED ACTION: {'agent0': [0.1004, 0.5], 'agent1': [0.1004, 0.5]}\n",
      "ACTION = {'agent0': [0.1004, 0.5], 'agent1': [0.1004, 0.5]}\n",
      "step reward {'agent0': 0.2361269704705572, 'agent1': 0.24900919970129443}\n",
      "STEP: 41\n",
      "DETERMINED ACTION: {'agent0': [0.10041, 0.5], 'agent1': [0.10041, 0.5]}\n",
      "ACTION = {'agent0': [0.10041, 0.5], 'agent1': [0.10041, 0.5]}\n",
      "step reward {'agent0': 0.23168517448967663, 'agent1': 0.24379909839065372}\n",
      "STEP: 42\n",
      "DETERMINED ACTION: {'agent0': [0.10042000000000001, 0.5], 'agent1': [0.10042000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10042000000000001, 0.5], 'agent1': [0.10042000000000001, 0.5]}\n",
      "step reward {'agent0': 0.22649719879575614, 'agent1': 0.2376947439078021}\n",
      "STEP: 43\n",
      "DETERMINED ACTION: {'agent0': [0.10043, 0.5], 'agent1': [0.10043, 0.5]}\n",
      "ACTION = {'agent0': [0.10043, 0.5], 'agent1': [0.10043, 0.5]}\n",
      "step reward {'agent0': 0.2205630330327143, 'agent1': 0.2308497635421174}\n",
      "STEP: 44\n",
      "DETERMINED ACTION: {'agent0': [0.10044, 0.5], 'agent1': [0.10044, 0.5]}\n",
      "ACTION = {'agent0': [0.10044, 0.5], 'agent1': [0.10044, 0.5]}\n",
      "step reward {'agent0': 0.21388346304727712, 'agent1': 0.22308091597720336}\n",
      "STEP: 45\n",
      "DETERMINED ACTION: {'agent0': [0.10045000000000001, 0.5], 'agent1': [0.10045000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10045000000000001, 0.5], 'agent1': [0.10045000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20639745008840882, 'agent1': 0.2143892459647707}\n",
      "STEP: 46\n",
      "DETERMINED ACTION: {'agent0': [0.10046000000000001, 0.5], 'agent1': [0.10046000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10046000000000001, 0.5], 'agent1': [0.10046000000000001, 0.5]}\n",
      "step reward {'agent0': 0.19810524139039576, 'agent1': 0.20480553080113528}\n",
      "STEP: 47\n",
      "DETERMINED ACTION: {'agent0': [0.10047, 0.5], 'agent1': [0.10047, 0.5]}\n",
      "ACTION = {'agent0': [0.10047, 0.5], 'agent1': [0.10047, 0.5]}\n",
      "step reward {'agent0': 0.18897711397151717, 'agent1': 0.19423833341804375}\n",
      "STEP: 48\n",
      "DETERMINED ACTION: {'agent0': [0.10048, 0.5], 'agent1': [0.10048, 0.5]}\n",
      "ACTION = {'agent0': [0.10048, 0.5], 'agent1': [0.10048, 0.5]}\n",
      "step reward {'agent0': 0.17898253772884165, 'agent1': 0.18271923379290334}\n",
      "STEP: 49\n",
      "DETERMINED ACTION: {'agent0': [0.10049000000000001, 0.5], 'agent1': [0.10049000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10049000000000001, 0.5], 'agent1': [0.10049000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1680917865311754, 'agent1': 0.17018630064627993}\n",
      "STEP: 50\n",
      "DETERMINED ACTION: {'agent0': [0.1005, 0.5], 'agent1': [0.1005, 0.5]}\n",
      "ACTION = {'agent0': [0.1005, 0.5], 'agent1': [0.1005, 0.5]}\n",
      "step reward {'agent0': 0.15630431166243253, 'agent1': 0.15654925162827482}\n",
      "STEP: 51\n",
      "DETERMINED ACTION: {'agent0': [0.10051, 0.5], 'agent1': [0.10051, 0.5]}\n",
      "ACTION = {'agent0': [0.10051, 0.5], 'agent1': [0.10051, 0.5]}\n",
      "step reward {'agent0': 0.14356066328962858, 'agent1': 0.14177806950832406}\n",
      "STEP: 52\n",
      "DETERMINED ACTION: {'agent0': [0.10052000000000001, 0.5], 'agent1': [0.10052000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10052000000000001, 0.5], 'agent1': [0.10052000000000001, 0.5]}\n",
      "step reward {'agent0': 0.12979899340145007, 'agent1': 0.1259646443415403}\n",
      "STEP: 53\n",
      "DETERMINED ACTION: {'agent0': [0.10053000000000001, 0.5], 'agent1': [0.10053000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10053000000000001, 0.5], 'agent1': [0.10053000000000001, 0.5]}\n",
      "step reward {'agent0': 0.11505115327016069, 'agent1': 0.10889532467457341}\n",
      "STEP: 54\n",
      "DETERMINED ACTION: {'agent0': [0.10054, 0.5], 'agent1': [0.10054, 0.5]}\n",
      "ACTION = {'agent0': [0.10054, 0.5], 'agent1': [0.10054, 0.5]}\n",
      "step reward {'agent0': 0.09925635212779294, 'agent1': 0.09072435936624401}\n",
      "STEP: 55\n",
      "DETERMINED ACTION: {'agent0': [0.10055, 0.5], 'agent1': [0.10055, 0.5]}\n",
      "ACTION = {'agent0': [0.10055, 0.5], 'agent1': [0.10055, 0.5]}\n",
      "step reward {'agent0': 0.08241431225594753, 'agent1': 0.07123735948982779}\n",
      "STEP: 56\n",
      "DETERMINED ACTION: {'agent0': [0.10056000000000001, 0.5], 'agent1': [0.10056000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10056000000000001, 0.5], 'agent1': [0.10056000000000001, 0.5]}\n",
      "step reward {'agent0': 0.06443451709623038, 'agent1': 0.050465973516793716}\n",
      "STEP: 57\n",
      "DETERMINED ACTION: {'agent0': [0.10057, 0.5], 'agent1': [0.10057, 0.5]}\n",
      "ACTION = {'agent0': [0.10057, 0.5], 'agent1': [0.10057, 0.5]}\n",
      "step reward {'agent0': 0.045286723943816165, 'agent1': 0.028471627854599557}\n",
      "STEP: 58\n",
      "DETERMINED ACTION: {'agent0': [0.10058, 0.5], 'agent1': [0.10058, 0.5]}\n",
      "ACTION = {'agent0': [0.10058, 0.5], 'agent1': [0.10058, 0.5]}\n",
      "step reward {'agent0': 0.02500143643323738, 'agent1': 0.005041335703969585}\n",
      "STEP: 59\n",
      "DETERMINED ACTION: {'agent0': [0.10059, 0.5], 'agent1': [0.10059, 0.5]}\n",
      "ACTION = {'agent0': [0.10059, 0.5], 'agent1': [0.10059, 0.5]}\n",
      "step reward {'agent0': 0.003457640124702732, 'agent1': -0.01976368554394925}\n",
      "STEP: 60\n",
      "DETERMINED ACTION: {'agent0': [0.10060000000000001, 0.5], 'agent1': [0.10060000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10060000000000001, 0.5], 'agent1': [0.10060000000000001, 0.5]}\n",
      "step reward {'agent0': -0.019283648609042192, 'agent1': -0.046003279170003575}\n",
      "STEP: 61\n",
      "DETERMINED ACTION: {'agent0': [0.10061, 0.5], 'agent1': [0.10061, 0.5]}\n",
      "ACTION = {'agent0': [0.10061, 0.5], 'agent1': [0.10061, 0.5]}\n",
      "step reward {'agent0': -0.04331294357959292, 'agent1': -0.07370797253047767}\n",
      "STEP: 62\n",
      "DETERMINED ACTION: {'agent0': [0.10062, 0.5], 'agent1': [0.10062, 0.5]}\n",
      "ACTION = {'agent0': [0.10062, 0.5], 'agent1': [0.10062, 0.5]}\n",
      "step reward {'agent0': -0.06866101947846259, 'agent1': -0.10296921281835958}\n",
      "STEP: 63\n",
      "DETERMINED ACTION: {'agent0': [0.10063000000000001, 0.5], 'agent1': [0.10063000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10063000000000001, 0.5], 'agent1': [0.10063000000000001, 0.5]}\n",
      "step reward {'agent0': -0.09538813986745598, 'agent1': -0.13378582182990462}\n",
      "STEP: 64\n",
      "DETERMINED ACTION: {'agent0': [0.10064000000000001, 0.5], 'agent1': [0.10064000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10064000000000001, 0.5], 'agent1': [0.10064000000000001, 0.5]}\n",
      "step reward {'agent0': -0.12346327350208519, 'agent1': -0.16615755323177317}\n",
      "STEP: 65\n",
      "DETERMINED ACTION: {'agent0': [0.10065, 0.5], 'agent1': [0.10065, 0.5]}\n",
      "ACTION = {'agent0': [0.10065, 0.5], 'agent1': [0.10065, 0.5]}\n",
      "step reward {'agent0': -0.15291641156165792, 'agent1': -0.2001754963289748}\n",
      "STEP: 66\n",
      "DETERMINED ACTION: {'agent0': [0.10066, 0.5], 'agent1': [0.10066, 0.5]}\n",
      "ACTION = {'agent0': [0.10066, 0.5], 'agent1': [0.10066, 0.5]}\n",
      "step reward {'agent0': -0.18383885645887188, 'agent1': -0.2357778318076822}\n",
      "STEP: 67\n",
      "DETERMINED ACTION: {'agent0': [0.10067000000000001, 0.5], 'agent1': [0.10067000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10067000000000001, 0.5], 'agent1': [0.10067000000000001, 0.5]}\n",
      "step reward {'agent0': -0.21627586108170105, 'agent1': -0.27317736045170704}\n",
      "STEP: 68\n",
      "DETERMINED ACTION: {'agent0': [0.10068, 0.5], 'agent1': [0.10068, 0.5]}\n",
      "ACTION = {'agent0': [0.10068, 0.5], 'agent1': [0.10068, 0.5]}\n",
      "step reward {'agent0': -0.25022690999247843, 'agent1': -0.3122822447786945}\n",
      "STEP: 69\n",
      "DETERMINED ACTION: {'agent0': [0.10069, 0.5], 'agent1': [0.10069, 0.5]}\n",
      "ACTION = {'agent0': [0.10069, 0.5], 'agent1': [0.10069, 0.5]}\n",
      "step reward {'agent0': -0.2856912165061307, 'agent1': -0.3531533607733105}\n",
      "STEP: 70\n",
      "DETERMINED ACTION: {'agent0': [0.10070000000000001, 0.5], 'agent1': [0.10070000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10070000000000001, 0.5], 'agent1': [0.10070000000000001, 0.5]}\n",
      "step reward {'agent0': -0.32274509626811887, 'agent1': -0.39582025085072137}\n",
      "STEP: 71\n",
      "DETERMINED ACTION: {'agent0': [0.10071000000000001, 0.5], 'agent1': [0.10071000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10071000000000001, 0.5], 'agent1': [0.10071000000000001, 0.5]}\n",
      "step reward {'agent0': -0.36140275289725854, 'agent1': -0.4403432197184992}\n",
      "STEP: 72\n",
      "DETERMINED ACTION: {'agent0': [0.10072, 0.5], 'agent1': [0.10072, 0.5]}\n",
      "ACTION = {'agent0': [0.10072, 0.5], 'agent1': [0.10072, 0.5]}\n",
      "step reward {'agent0': -0.401694878118788, 'agent1': -0.4866913187310903}\n",
      "STEP: 73\n",
      "DETERMINED ACTION: {'agent0': [0.10073, 0.5], 'agent1': [0.10073, 0.5]}\n",
      "ACTION = {'agent0': [0.10073, 0.5], 'agent1': [0.10073, 0.5]}\n",
      "step reward {'agent0': -0.44366601367967884, 'agent1': -0.5349245072246729}\n",
      "STEP: 74\n",
      "DETERMINED ACTION: {'agent0': [0.10074000000000001, 0.5], 'agent1': [0.10074000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10074000000000001, 0.5], 'agent1': [0.10074000000000001, 0.5]}\n",
      "step reward {'agent0': -0.48730082341042336, 'agent1': -0.5851342755996859}\n",
      "STEP: 75\n",
      "DETERMINED ACTION: {'agent0': [0.10075, 0.5], 'agent1': [0.10075, 0.5]}\n",
      "ACTION = {'agent0': [0.10075, 0.5], 'agent1': [0.10075, 0.5]}\n",
      "step reward {'agent0': -0.5326742744934082, 'agent1': -0.6371975486193335}\n",
      "STEP: 76\n",
      "DETERMINED ACTION: {'agent0': [0.10076, 0.5], 'agent1': [0.10076, 0.5]}\n",
      "ACTION = {'agent0': [0.10076, 0.5], 'agent1': [0.10076, 0.5]}\n",
      "step reward {'agent0': -0.5797574442098303, 'agent1': -0.6912970034259398}\n",
      "STEP: 77\n",
      "DETERMINED ACTION: {'agent0': [0.10077000000000001, 0.5], 'agent1': [0.10077000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10077000000000001, 0.5], 'agent1': [0.10077000000000001, 0.5]}\n",
      "step reward {'agent0': -0.6285944300020255, 'agent1': -0.7473097266478252}\n",
      "STEP: 78\n",
      "DETERMINED ACTION: {'agent0': [0.10078000000000001, 0.5], 'agent1': [0.10078000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10078000000000001, 0.5], 'agent1': [0.10078000000000001, 0.5]}\n",
      "step reward {'agent0': -0.6792280868467973, 'agent1': -0.8052959183147426}\n",
      "STEP: 79\n",
      "DETERMINED ACTION: {'agent0': [0.10079, 0.5], 'agent1': [0.10079, 0.5]}\n",
      "ACTION = {'agent0': [0.10079, 0.5], 'agent1': [0.10079, 0.5]}\n",
      "step reward {'agent0': -0.731645682202573, 'agent1': -0.8652858012219871}\n",
      "STEP: 80\n",
      "DETERMINED ACTION: {'agent0': [0.1008, 0.5], 'agent1': [0.1008, 0.5]}\n",
      "ACTION = {'agent0': [0.1008, 0.5], 'agent1': [0.1008, 0.5]}\n",
      "step reward {'agent0': -0.7858607605880765, 'agent1': -0.9273087830276453}\n",
      "STEP: 81\n",
      "DETERMINED ACTION: {'agent0': [0.10081000000000001, 0.5], 'agent1': [0.10081000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10081000000000001, 0.5], 'agent1': [0.10081000000000001, 0.5]}\n",
      "step reward {'agent0': -0.8418730857301441, 'agent1': -0.9912731012950149}\n",
      "STEP: 82\n",
      "DETERMINED ACTION: {'agent0': [0.10082, 0.5], 'agent1': [0.10082, 0.5]}\n",
      "ACTION = {'agent0': [0.10082, 0.5], 'agent1': [0.10082, 0.5]}\n",
      "step reward {'agent0': -0.8996966162951741, 'agent1': -1.0572999984657554}\n",
      "STEP: 83\n",
      "DETERMINED ACTION: {'agent0': [0.10083, 0.5], 'agent1': [0.10083, 0.5]}\n",
      "ACTION = {'agent0': [0.10083, 0.5], 'agent1': [0.10083, 0.5]}\n",
      "step reward {'agent0': -0.9593614334683762, 'agent1': -1.125266277013098}\n",
      "STEP: 84\n",
      "DETERMINED ACTION: {'agent0': [0.10084, 0.5], 'agent1': [0.10084, 0.5]}\n",
      "ACTION = {'agent0': [0.10084, 0.5], 'agent1': [0.10084, 0.5]}\n",
      "step reward {'agent0': -1.020852209682443, 'agent1': -1.1951716482636985}\n",
      "STEP: 85\n",
      "DETERMINED ACTION: {'agent0': [0.10085000000000001, 0.5], 'agent1': [0.10085000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10085000000000001, 0.5], 'agent1': [0.10085000000000001, 0.5]}\n",
      "step reward {'agent0': -1.0841682902821097, 'agent1': -1.2671372237638687}\n",
      "STEP: 86\n",
      "DETERMINED ACTION: {'agent0': [0.10086, 0.5], 'agent1': [0.10086, 0.5]}\n",
      "ACTION = {'agent0': [0.10086, 0.5], 'agent1': [0.10086, 0.5]}\n",
      "step reward {'agent0': -1.1492775600417708, 'agent1': -1.3410403405298623}\n",
      "STEP: 87\n",
      "DETERMINED ACTION: {'agent0': [0.10087, 0.5], 'agent1': [0.10087, 0.5]}\n",
      "ACTION = {'agent0': [0.10087, 0.5], 'agent1': [0.10087, 0.5]}\n",
      "step reward {'agent0': -1.2162246292373984, 'agent1': -1.4167579007052535}\n",
      "STEP: 88\n",
      "DETERMINED ACTION: {'agent0': [0.10088000000000001, 0.5], 'agent1': [0.10088000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10088000000000001, 0.5], 'agent1': [0.10088000000000001, 0.5]}\n",
      "step reward {'agent0': -1.2849040103069216, 'agent1': -1.4944418336912106}\n",
      "STEP: 89\n",
      "DETERMINED ACTION: {'agent0': [0.10089000000000001, 0.5], 'agent1': [0.10089000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10089000000000001, 0.5], 'agent1': [0.10089000000000001, 0.5]}\n",
      "step reward {'agent0': -1.3553907092443334, 'agent1': -4.669572581608824}\n",
      "STEP: 90\n",
      "DETERMINED ACTION: {'agent0': [0.1009, 0.5], 'agent1': [0.1009, 0.5]}\n",
      "ACTION = {'agent0': [0.1009, 0.5], 'agent1': [0.1009, 0.5]}\n",
      "step reward {'agent0': -1.4276223900192242, 'agent1': -4.679531715788292}\n",
      "STEP: 91\n",
      "DETERMINED ACTION: {'agent0': [0.10091, 0.5], 'agent1': [0.10091, 0.5]}\n",
      "ACTION = {'agent0': [0.10091, 0.5], 'agent1': [0.10091, 0.5]}\n",
      "step reward {'agent0': -1.501553658476438, 'agent1': -4.690458657305194}\n",
      "STEP: 92\n",
      "DETERMINED ACTION: {'agent0': [0.10092000000000001, 0.5], 'agent1': [0.10092000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10092000000000001, 0.5], 'agent1': [0.10092000000000001, 0.5]}\n",
      "step reward {'agent0': -1.5771675456871166, 'agent1': -4.702354319488141}\n",
      "STEP: 93\n",
      "DETERMINED ACTION: {'agent0': [0.10093, 0.5], 'agent1': [0.10093, 0.5]}\n",
      "ACTION = {'agent0': [0.10093, 0.5], 'agent1': [0.10093, 0.5]}\n",
      "step reward {'agent0': -1.6544181626381487, 'agent1': -4.715158489186451}\n",
      "STEP: 94\n",
      "DETERMINED ACTION: {'agent0': [0.10094, 0.5], 'agent1': [0.10094, 0.5]}\n",
      "ACTION = {'agent0': [0.10094, 0.5], 'agent1': [0.10094, 0.5]}\n",
      "step reward {'agent0': -1.7332739628258498, 'agent1': -4.728719533799977}\n",
      "STEP: 95\n",
      "DETERMINED ACTION: {'agent0': [0.10095000000000001, 0.5], 'agent1': [0.10095000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10095000000000001, 0.5], 'agent1': [0.10095000000000001, 0.5]}\n",
      "step reward {'agent0': -1.8136733645944256, 'agent1': -4.743099450874215}\n",
      "STEP: 96\n",
      "DETERMINED ACTION: {'agent0': [0.10096000000000001, 0.5], 'agent1': [0.10096000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10096000000000001, 0.5], 'agent1': [0.10096000000000001, 0.5]}\n",
      "step reward {'agent0': -1.895600750582946, 'agent1': -4.758054758090967}\n",
      "STEP: 97\n",
      "DETERMINED ACTION: {'agent0': [0.10097, 0.5], 'agent1': [0.10097, 0.5]}\n",
      "ACTION = {'agent0': [0.10097, 0.5], 'agent1': [0.10097, 0.5]}\n",
      "step reward {'agent0': -1.978932461614655, 'agent1': -4.773586741773032}\n",
      "STEP: 98\n",
      "DETERMINED ACTION: {'agent0': [0.10098, 0.5], 'agent1': [0.10098, 0.5]}\n",
      "ACTION = {'agent0': [0.10098, 0.5], 'agent1': [0.10098, 0.5]}\n",
      "step reward {'agent0': -2.0636072397842145, 'agent1': -4.789604349248121}\n",
      "STEP: 99\n",
      "DETERMINED ACTION: {'agent0': [0.10099000000000001, 0.5], 'agent1': [0.10099000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10099000000000001, 0.5], 'agent1': [0.10099000000000001, 0.5]}\n",
      "step reward {'agent0': -2.1496088783536194, 'agent1': -4.806047570038423}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 3\n",
      "STEP: 0\n",
      "DETERMINED ACTION: {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "step reward {'agent0': 0.0, 'agent1': 0.0}\n",
      "STEP: 1\n",
      "DETERMINED ACTION: {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "ACTION = {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "step reward {'agent0': 0.0038526555422579946, 'agent1': 0.004135040017045982}\n",
      "STEP: 2\n",
      "DETERMINED ACTION: {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "step reward {'agent0': 0.01736952331648215, 'agent1': 0.01858249846210685}\n",
      "STEP: 3\n",
      "DETERMINED ACTION: {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "step reward {'agent0': 0.031146377108932685, 'agent1': 0.03326491356415968}\n",
      "STEP: 4\n",
      "DETERMINED ACTION: {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "ACTION = {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "step reward {'agent0': 0.04440653490555097, 'agent1': 0.04752700047206012}\n",
      "STEP: 5\n",
      "DETERMINED ACTION: {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "ACTION = {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "step reward {'agent0': 0.05722315501278951, 'agent1': 0.061258810639572725}\n",
      "STEP: 6\n",
      "DETERMINED ACTION: {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "step reward {'agent0': 0.0697701561301046, 'agent1': 0.07460161797301573}\n",
      "STEP: 7\n",
      "DETERMINED ACTION: {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "ACTION = {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "step reward {'agent0': 0.08185168189329399, 'agent1': 0.08754333648014992}\n",
      "STEP: 8\n",
      "DETERMINED ACTION: {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "ACTION = {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "step reward {'agent0': 0.09352529335224245, 'agent1': 0.10008022845947041}\n",
      "STEP: 9\n",
      "DETERMINED ACTION: {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "step reward {'agent0': 0.10481378900734901, 'agent1': 0.11217525188540045}\n",
      "STEP: 10\n",
      "DETERMINED ACTION: {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1157129144535832, 'agent1': 0.12385333999079096}\n",
      "STEP: 11\n",
      "DETERMINED ACTION: {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "ACTION = {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "step reward {'agent0': 0.1262213475412153, 'agent1': 0.13511436783483488}\n",
      "STEP: 12\n",
      "DETERMINED ACTION: {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "ACTION = {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "step reward {'agent0': 0.13634121315703499, 'agent1': 0.14595952800487072}\n",
      "STEP: 13\n",
      "DETERMINED ACTION: {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1460735712330344, 'agent1': 0.1563289763156302}\n",
      "STEP: 14\n",
      "DETERMINED ACTION: {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "ACTION = {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "step reward {'agent0': 0.15541868313394386, 'agent1': 0.1662849479755415}\n",
      "STEP: 15\n",
      "DETERMINED ACTION: {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "ACTION = {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "step reward {'agent0': 0.16437708022658917, 'agent1': 0.17579624822253034}\n",
      "STEP: 16\n",
      "DETERMINED ACTION: {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "ACTION = {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "step reward {'agent0': 0.172825888977618, 'agent1': 0.18492378080641061}\n",
      "STEP: 17\n",
      "DETERMINED ACTION: {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "step reward {'agent0': 0.18094927867844784, 'agent1': 0.1934862957290193}\n",
      "STEP: 18\n",
      "DETERMINED ACTION: {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "ACTION = {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "step reward {'agent0': 0.18862464349410019, 'agent1': 0.20178683347265308}\n",
      "STEP: 19\n",
      "DETERMINED ACTION: {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "ACTION = {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "step reward {'agent0': 0.19585277335928464, 'agent1': 0.20952260727064792}\n",
      "STEP: 20\n",
      "DETERMINED ACTION: {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20266391293275338, 'agent1': 0.21669282033876464}\n",
      "STEP: 21\n",
      "DETERMINED ACTION: {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20905913197290127, 'agent1': 0.2235422691307034}\n",
      "STEP: 22\n",
      "DETERMINED ACTION: {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "ACTION = {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "step reward {'agent0': 0.21500709893949915, 'agent1': 0.2298567959083872}\n",
      "STEP: 23\n",
      "DETERMINED ACTION: {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "ACTION = {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "step reward {'agent0': 0.22047862820241032, 'agent1': 0.23569848587628495}\n",
      "STEP: 24\n",
      "DETERMINED ACTION: {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "step reward {'agent0': 0.22556473521857456, 'agent1': 0.24106853961641284}\n",
      "STEP: 25\n",
      "DETERMINED ACTION: {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "ACTION = {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "step reward {'agent0': 0.2301741291411029, 'agent1': 0.24590457763296747}\n",
      "STEP: 26\n",
      "DETERMINED ACTION: {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "ACTION = {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "step reward {'agent0': 0.23427707819948046, 'agent1': 0.2502379111658073}\n",
      "STEP: 27\n",
      "DETERMINED ACTION: {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2379346168747179, 'agent1': 0.254069596237227}\n",
      "STEP: 28\n",
      "DETERMINED ACTION: {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24111621721929616, 'agent1': 0.25733713266445635}\n",
      "STEP: 29\n",
      "DETERMINED ACTION: {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "ACTION = {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "step reward {'agent0': 0.24373085892856883, 'agent1': 0.26004223610238325}\n",
      "STEP: 30\n",
      "DETERMINED ACTION: {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "ACTION = {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "step reward {'agent0': 0.24590086807487066, 'agent1': 0.26221608247272005}\n",
      "STEP: 31\n",
      "DETERMINED ACTION: {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2475352144369064, 'agent1': 0.26379682596068005}\n",
      "STEP: 32\n",
      "DETERMINED ACTION: {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "ACTION = {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "step reward {'agent0': 0.24860337945049588, 'agent1': 0.26484655637077226}\n",
      "STEP: 33\n",
      "DETERMINED ACTION: {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "ACTION = {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "step reward {'agent0': 0.24913559949062025, 'agent1': 0.2651831057182559}\n",
      "STEP: 34\n",
      "DETERMINED ACTION: {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2491024206288558, 'agent1': 0.26492785921826817}\n",
      "STEP: 35\n",
      "DETERMINED ACTION: {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24850409257288109, 'agent1': 0.26402030454888425}\n",
      "STEP: 36\n",
      "DETERMINED ACTION: {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "ACTION = {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "step reward {'agent0': 0.24727958048560833, 'agent1': 0.2624605548971004}\n",
      "STEP: 37\n",
      "DETERMINED ACTION: {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "ACTION = {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "step reward {'agent0': 0.24545992182444798, 'agent1': 0.26018904304213286}\n",
      "STEP: 38\n",
      "DETERMINED ACTION: {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24304512040524628, 'agent1': 0.257204424524462}\n",
      "STEP: 39\n",
      "DETERMINED ACTION: {'agent0': [0.10039000000000001, 0.5], 'agent1': [0.10039000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10039000000000001, 0.5], 'agent1': [0.10039000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2398831022812552, 'agent1': 0.25350828741452336}\n",
      "STEP: 40\n",
      "DETERMINED ACTION: {'agent0': [0.1004, 0.5], 'agent1': [0.1004, 0.5]}\n",
      "ACTION = {'agent0': [0.1004, 0.5], 'agent1': [0.1004, 0.5]}\n",
      "step reward {'agent0': 0.2361269704705572, 'agent1': 0.24900919970129443}\n",
      "STEP: 41\n",
      "DETERMINED ACTION: {'agent0': [0.10041, 0.5], 'agent1': [0.10041, 0.5]}\n",
      "ACTION = {'agent0': [0.10041, 0.5], 'agent1': [0.10041, 0.5]}\n",
      "step reward {'agent0': 0.23168517448967663, 'agent1': 0.24379910038705377}\n",
      "STEP: 42\n",
      "DETERMINED ACTION: {'agent0': [0.10042000000000001, 0.5], 'agent1': [0.10042000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10042000000000001, 0.5], 'agent1': [0.10042000000000001, 0.5]}\n",
      "step reward {'agent0': 0.22649719879575614, 'agent1': 0.23769474630070475}\n",
      "STEP: 43\n",
      "DETERMINED ACTION: {'agent0': [0.10043, 0.5], 'agent1': [0.10043, 0.5]}\n",
      "ACTION = {'agent0': [0.10043, 0.5], 'agent1': [0.10043, 0.5]}\n",
      "step reward {'agent0': 0.2205630330327143, 'agent1': 0.23084976551065894}\n",
      "STEP: 44\n",
      "DETERMINED ACTION: {'agent0': [0.10044, 0.5], 'agent1': [0.10044, 0.5]}\n",
      "ACTION = {'agent0': [0.10044, 0.5], 'agent1': [0.10044, 0.5]}\n",
      "step reward {'agent0': 0.21388346304727712, 'agent1': 0.22308091837462174}\n",
      "STEP: 45\n",
      "DETERMINED ACTION: {'agent0': [0.10045000000000001, 0.5], 'agent1': [0.10045000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10045000000000001, 0.5], 'agent1': [0.10045000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20639745008840882, 'agent1': 0.21438924882508525}\n",
      "STEP: 46\n",
      "DETERMINED ACTION: {'agent0': [0.10046000000000001, 0.5], 'agent1': [0.10046000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10046000000000001, 0.5], 'agent1': [0.10046000000000001, 0.5]}\n",
      "step reward {'agent0': 0.19810524139039576, 'agent1': 0.20480553415904001}\n",
      "STEP: 47\n",
      "DETERMINED ACTION: {'agent0': [0.10047, 0.5], 'agent1': [0.10047, 0.5]}\n",
      "ACTION = {'agent0': [0.10047, 0.5], 'agent1': [0.10047, 0.5]}\n",
      "step reward {'agent0': 0.18897711397151717, 'agent1': 0.1942380710810503}\n",
      "STEP: 48\n",
      "DETERMINED ACTION: {'agent0': [0.10048, 0.5], 'agent1': [0.10048, 0.5]}\n",
      "ACTION = {'agent0': [0.10048, 0.5], 'agent1': [0.10048, 0.5]}\n",
      "step reward {'agent0': 0.17898253772884165, 'agent1': 0.18271869605652702}\n",
      "STEP: 49\n",
      "DETERMINED ACTION: {'agent0': [0.10049000000000001, 0.5], 'agent1': [0.10049000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10049000000000001, 0.5], 'agent1': [0.10049000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1680917865311754, 'agent1': 0.17018609640814342}\n",
      "STEP: 50\n",
      "DETERMINED ACTION: {'agent0': [0.1005, 0.5], 'agent1': [0.1005, 0.5]}\n",
      "ACTION = {'agent0': [0.1005, 0.5], 'agent1': [0.1005, 0.5]}\n",
      "step reward {'agent0': 0.15630431166243253, 'agent1': 0.15654924371791923}\n",
      "STEP: 51\n",
      "DETERMINED ACTION: {'agent0': [0.10051, 0.5], 'agent1': [0.10051, 0.5]}\n",
      "ACTION = {'agent0': [0.10051, 0.5], 'agent1': [0.10051, 0.5]}\n",
      "step reward {'agent0': 0.14356066328962858, 'agent1': 0.14177806359097478}\n",
      "STEP: 52\n",
      "DETERMINED ACTION: {'agent0': [0.10052000000000001, 0.5], 'agent1': [0.10052000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10052000000000001, 0.5], 'agent1': [0.10052000000000001, 0.5]}\n",
      "step reward {'agent0': 0.12979899340145007, 'agent1': 0.1259646395770696}\n",
      "STEP: 53\n",
      "DETERMINED ACTION: {'agent0': [0.10053000000000001, 0.5], 'agent1': [0.10053000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10053000000000001, 0.5], 'agent1': [0.10053000000000001, 0.5]}\n",
      "step reward {'agent0': 0.11505115327016069, 'agent1': 0.10889531748837311}\n",
      "STEP: 54\n",
      "DETERMINED ACTION: {'agent0': [0.10054, 0.5], 'agent1': [0.10054, 0.5]}\n",
      "ACTION = {'agent0': [0.10054, 0.5], 'agent1': [0.10054, 0.5]}\n",
      "step reward {'agent0': 0.09925635212779294, 'agent1': 0.0907243503795282}\n",
      "STEP: 55\n",
      "DETERMINED ACTION: {'agent0': [0.10055, 0.5], 'agent1': [0.10055, 0.5]}\n",
      "ACTION = {'agent0': [0.10055, 0.5], 'agent1': [0.10055, 0.5]}\n",
      "step reward {'agent0': 0.08241431401731703, 'agent1': 0.07123734876105403}\n",
      "STEP: 56\n",
      "DETERMINED ACTION: {'agent0': [0.10056000000000001, 0.5], 'agent1': [0.10056000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10056000000000001, 0.5], 'agent1': [0.10056000000000001, 0.5]}\n",
      "step reward {'agent0': 0.06443451835843272, 'agent1': 0.050465959777381775}\n",
      "STEP: 57\n",
      "DETERMINED ACTION: {'agent0': [0.10057, 0.5], 'agent1': [0.10057, 0.5]}\n",
      "ACTION = {'agent0': [0.10057, 0.5], 'agent1': [0.10057, 0.5]}\n",
      "step reward {'agent0': 0.045286727359655776, 'agent1': 0.028471611095679195}\n",
      "STEP: 58\n",
      "DETERMINED ACTION: {'agent0': [0.10058, 0.5], 'agent1': [0.10058, 0.5]}\n",
      "ACTION = {'agent0': [0.10058, 0.5], 'agent1': [0.10058, 0.5]}\n",
      "step reward {'agent0': 0.024955664416891787, 'agent1': 0.0050413143016242445}\n",
      "STEP: 59\n",
      "DETERMINED ACTION: {'agent0': [0.10059, 0.5], 'agent1': [0.10059, 0.5]}\n",
      "ACTION = {'agent0': [0.10059, 0.5], 'agent1': [0.10059, 0.5]}\n",
      "step reward {'agent0': 0.003473169082184757, 'agent1': -0.0197635750501437}\n",
      "STEP: 60\n",
      "DETERMINED ACTION: {'agent0': [0.10060000000000001, 0.5], 'agent1': [0.10060000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10060000000000001, 0.5], 'agent1': [0.10060000000000001, 0.5]}\n",
      "step reward {'agent0': -0.019298640037961223, 'agent1': -0.04600350169472878}\n",
      "STEP: 61\n",
      "DETERMINED ACTION: {'agent0': [0.10061, 0.5], 'agent1': [0.10061, 0.5]}\n",
      "ACTION = {'agent0': [0.10061, 0.5], 'agent1': [0.10061, 0.5]}\n",
      "step reward {'agent0': -0.043312669475703225, 'agent1': -0.07370819804677142}\n",
      "STEP: 62\n",
      "DETERMINED ACTION: {'agent0': [0.10062, 0.5], 'agent1': [0.10062, 0.5]}\n",
      "ACTION = {'agent0': [0.10062, 0.5], 'agent1': [0.10062, 0.5]}\n",
      "step reward {'agent0': -0.06867627354393702, 'agent1': -0.10296924159598164}\n",
      "STEP: 63\n",
      "DETERMINED ACTION: {'agent0': [0.10063000000000001, 0.5], 'agent1': [0.10063000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10063000000000001, 0.5], 'agent1': [0.10063000000000001, 0.5]}\n",
      "step reward {'agent0': -0.09535735294592274, 'agent1': -0.133785785713179}\n",
      "STEP: 64\n",
      "DETERMINED ACTION: {'agent0': [0.10064000000000001, 0.5], 'agent1': [0.10064000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10064000000000001, 0.5], 'agent1': [0.10064000000000001, 0.5]}\n",
      "step reward {'agent0': -0.12343248228672565, 'agent1': -0.1661577848537158}\n",
      "STEP: 65\n",
      "DETERMINED ACTION: {'agent0': [0.10065, 0.5], 'agent1': [0.10065, 0.5]}\n",
      "ACTION = {'agent0': [0.10065, 0.5], 'agent1': [0.10065, 0.5]}\n",
      "step reward {'agent0': -0.1529316657298806, 'agent1': -0.20017559610980518}\n",
      "STEP: 66\n",
      "DETERMINED ACTION: {'agent0': [0.10066, 0.5], 'agent1': [0.10066, 0.5]}\n",
      "ACTION = {'agent0': [0.10066, 0.5], 'agent1': [0.10066, 0.5]}\n",
      "step reward {'agent0': -0.18386909701691678, 'agent1': -0.2357778696170314}\n",
      "STEP: 67\n",
      "DETERMINED ACTION: {'agent0': [0.10067000000000001, 0.5], 'agent1': [0.10067000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10067000000000001, 0.5], 'agent1': [0.10067000000000001, 0.5]}\n",
      "step reward {'agent0': -0.21627558418437542, 'agent1': -0.2731773986296212}\n",
      "STEP: 68\n",
      "DETERMINED ACTION: {'agent0': [0.10068, 0.5], 'agent1': [0.10068, 0.5]}\n",
      "ACTION = {'agent0': [0.10068, 0.5], 'agent1': [0.10068, 0.5]}\n",
      "step reward {'agent0': -0.25022663652433985, 'agent1': -0.3122822827984343}\n",
      "STEP: 69\n",
      "DETERMINED ACTION: {'agent0': [0.10069, 0.5], 'agent1': [0.10069, 0.5]}\n",
      "ACTION = {'agent0': [0.10069, 0.5], 'agent1': [0.10069, 0.5]}\n",
      "step reward {'agent0': -0.2856912140479132, 'agent1': -0.35315326936953517}\n",
      "STEP: 70\n",
      "DETERMINED ACTION: {'agent0': [0.10070000000000001, 0.5], 'agent1': [0.10070000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10070000000000001, 0.5], 'agent1': [0.10070000000000001, 0.5]}\n",
      "step reward {'agent0': -0.3227445640050616, 'agent1': -0.3958202284220428}\n",
      "STEP: 71\n",
      "DETERMINED ACTION: {'agent0': [0.10071000000000001, 0.5], 'agent1': [0.10071000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10071000000000001, 0.5], 'agent1': [0.10071000000000001, 0.5]}\n",
      "step reward {'agent0': -0.3614027565232638, 'agent1': -0.44034326283786196}\n",
      "STEP: 72\n",
      "DETERMINED ACTION: {'agent0': [0.10072, 0.5], 'agent1': [0.10072, 0.5]}\n",
      "ACTION = {'agent0': [0.10072, 0.5], 'agent1': [0.10072, 0.5]}\n",
      "step reward {'agent0': -0.40169461683094365, 'agent1': -0.4866913677045185}\n",
      "STEP: 73\n",
      "DETERMINED ACTION: {'agent0': [0.10073, 0.5], 'agent1': [0.10073, 0.5]}\n",
      "ACTION = {'agent0': [0.10073, 0.5], 'agent1': [0.10073, 0.5]}\n",
      "step reward {'agent0': -0.4436658846892818, 'agent1': -0.5349245552051671}\n",
      "STEP: 74\n",
      "DETERMINED ACTION: {'agent0': [0.10074000000000001, 0.5], 'agent1': [0.10074000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10074000000000001, 0.5], 'agent1': [0.10074000000000001, 0.5]}\n",
      "step reward {'agent0': -0.48730082990987167, 'agent1': -0.5851341895006041}\n",
      "STEP: 75\n",
      "DETERMINED ACTION: {'agent0': [0.10075, 0.5], 'agent1': [0.10075, 0.5]}\n",
      "ACTION = {'agent0': [0.10075, 0.5], 'agent1': [0.10075, 0.5]}\n",
      "step reward {'agent0': -0.5326742792912937, 'agent1': -0.6371974932890516}\n",
      "STEP: 76\n",
      "DETERMINED ACTION: {'agent0': [0.10076, 0.5], 'agent1': [0.10076, 0.5]}\n",
      "ACTION = {'agent0': [0.10076, 0.5], 'agent1': [0.10076, 0.5]}\n",
      "step reward {'agent0': -0.5797574538041977, 'agent1': -0.6912969799592563}\n",
      "STEP: 77\n",
      "DETERMINED ACTION: {'agent0': [0.10077000000000001, 0.5], 'agent1': [0.10077000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10077000000000001, 0.5], 'agent1': [0.10077000000000001, 0.5]}\n",
      "step reward {'agent0': -0.6285944395870958, 'agent1': -0.7473095698762369}\n",
      "STEP: 78\n",
      "DETERMINED ACTION: {'agent0': [0.10078000000000001, 0.5], 'agent1': [0.10078000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10078000000000001, 0.5], 'agent1': [0.10078000000000001, 0.5]}\n",
      "step reward {'agent0': -0.6792280956056292, 'agent1': -0.8052958279996254}\n",
      "STEP: 79\n",
      "DETERMINED ACTION: {'agent0': [0.10079, 0.5], 'agent1': [0.10079, 0.5]}\n",
      "ACTION = {'agent0': [0.10079, 0.5], 'agent1': [0.10079, 0.5]}\n",
      "step reward {'agent0': -0.7316456909943586, 'agent1': -0.8652857111026409}\n",
      "STEP: 80\n",
      "DETERMINED ACTION: {'agent0': [0.1008, 0.5], 'agent1': [0.1008, 0.5]}\n",
      "ACTION = {'agent0': [0.1008, 0.5], 'agent1': [0.1008, 0.5]}\n",
      "step reward {'agent0': -0.7858610364110963, 'agent1': -0.9273088319480154}\n",
      "STEP: 81\n",
      "DETERMINED ACTION: {'agent0': [0.10081000000000001, 0.5], 'agent1': [0.10081000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10081000000000001, 0.5], 'agent1': [0.10081000000000001, 0.5]}\n",
      "step reward {'agent0': -0.8418730907756637, 'agent1': -0.9912731161866577}\n",
      "STEP: 82\n",
      "DETERMINED ACTION: {'agent0': [0.10082, 0.5], 'agent1': [0.10082, 0.5]}\n",
      "ACTION = {'agent0': [0.10082, 0.5], 'agent1': [0.10082, 0.5]}\n",
      "step reward {'agent0': -0.8996966210002236, 'agent1': -1.0572999285842544}\n",
      "STEP: 83\n",
      "DETERMINED ACTION: {'agent0': [0.10083, 0.5], 'agent1': [0.10083, 0.5]}\n",
      "ACTION = {'agent0': [0.10083, 0.5], 'agent1': [0.10083, 0.5]}\n",
      "step reward {'agent0': -0.9593614383924367, 'agent1': -1.1252662404826483}\n",
      "STEP: 84\n",
      "DETERMINED ACTION: {'agent0': [0.10084, 0.5], 'agent1': [0.10084, 0.5]}\n",
      "ACTION = {'agent0': [0.10084, 0.5], 'agent1': [0.10084, 0.5]}\n",
      "step reward {'agent0': -1.0208522185223174, 'agent1': -1.195171561759842}\n",
      "STEP: 85\n",
      "DETERMINED ACTION: {'agent0': [0.10085000000000001, 0.5], 'agent1': [0.10085000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10085000000000001, 0.5], 'agent1': [0.10085000000000001, 0.5]}\n",
      "step reward {'agent0': -1.0841682989219183, 'agent1': -1.2671370957023391}\n",
      "STEP: 86\n",
      "DETERMINED ACTION: {'agent0': [0.10086, 0.5], 'agent1': [0.10086, 0.5]}\n",
      "ACTION = {'agent0': [0.10086, 0.5], 'agent1': [0.10086, 0.5]}\n",
      "step reward {'agent0': -1.1492775687656627, 'agent1': -1.341040154235752}\n",
      "STEP: 87\n",
      "DETERMINED ACTION: {'agent0': [0.10087, 0.5], 'agent1': [0.10087, 0.5]}\n",
      "ACTION = {'agent0': [0.10087, 0.5], 'agent1': [0.10087, 0.5]}\n",
      "step reward {'agent0': -1.2162246379440855, 'agent1': -1.4167576813382585}\n",
      "STEP: 88\n",
      "DETERMINED ACTION: {'agent0': [0.10088000000000001, 0.5], 'agent1': [0.10088000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10088000000000001, 0.5], 'agent1': [0.10088000000000001, 0.5]}\n",
      "step reward {'agent0': -1.2849040190071872, 'agent1': -1.4944415972682155}\n",
      "STEP: 89\n",
      "DETERMINED ACTION: {'agent0': [0.10089000000000001, 0.5], 'agent1': [0.10089000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10089000000000001, 0.5], 'agent1': [0.10089000000000001, 0.5]}\n",
      "step reward {'agent0': -1.3553907178424365, 'agent1': -4.669542424464415}\n",
      "STEP: 90\n",
      "DETERMINED ACTION: {'agent0': [0.1009, 0.5], 'agent1': [0.1009, 0.5]}\n",
      "ACTION = {'agent0': [0.1009, 0.5], 'agent1': [0.1009, 0.5]}\n",
      "step reward {'agent0': -1.4276223986143628, 'agent1': -4.6795321182860325}\n",
      "STEP: 91\n",
      "DETERMINED ACTION: {'agent0': [0.10091, 0.5], 'agent1': [0.10091, 0.5]}\n",
      "ACTION = {'agent0': [0.10091, 0.5], 'agent1': [0.10091, 0.5]}\n",
      "step reward {'agent0': -1.5015536671365095, 'agent1': -4.6904590524539485}\n",
      "STEP: 92\n",
      "DETERMINED ACTION: {'agent0': [0.10092000000000001, 0.5], 'agent1': [0.10092000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10092000000000001, 0.5], 'agent1': [0.10092000000000001, 0.5]}\n",
      "step reward {'agent0': -1.5771675543973553, 'agent1': -4.702354745554969}\n",
      "STEP: 93\n",
      "DETERMINED ACTION: {'agent0': [0.10093, 0.5], 'agent1': [0.10093, 0.5]}\n",
      "ACTION = {'agent0': [0.10093, 0.5], 'agent1': [0.10093, 0.5]}\n",
      "step reward {'agent0': -1.6544181712838584, 'agent1': -4.7151589294227305}\n",
      "STEP: 94\n",
      "DETERMINED ACTION: {'agent0': [0.10094, 0.5], 'agent1': [0.10094, 0.5]}\n",
      "ACTION = {'agent0': [0.10094, 0.5], 'agent1': [0.10094, 0.5]}\n",
      "step reward {'agent0': -1.7332739714756502, 'agent1': -4.728720054093723}\n",
      "STEP: 95\n",
      "DETERMINED ACTION: {'agent0': [0.10095000000000001, 0.5], 'agent1': [0.10095000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10095000000000001, 0.5], 'agent1': [0.10095000000000001, 0.5]}\n",
      "step reward {'agent0': -1.8136733732377, 'agent1': -4.743099989101647}\n",
      "STEP: 96\n",
      "DETERMINED ACTION: {'agent0': [0.10096000000000001, 0.5], 'agent1': [0.10096000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10096000000000001, 0.5], 'agent1': [0.10096000000000001, 0.5]}\n",
      "step reward {'agent0': -1.8956007594207949, 'agent1': -4.758055401168853}\n",
      "STEP: 97\n",
      "DETERMINED ACTION: {'agent0': [0.10097, 0.5], 'agent1': [0.10097, 0.5]}\n",
      "ACTION = {'agent0': [0.10097, 0.5], 'agent1': [0.10097, 0.5]}\n",
      "step reward {'agent0': -1.9789324702117872, 'agent1': -4.773587320420233}\n",
      "STEP: 98\n",
      "DETERMINED ACTION: {'agent0': [0.10098, 0.5], 'agent1': [0.10098, 0.5]}\n",
      "ACTION = {'agent0': [0.10098, 0.5], 'agent1': [0.10098, 0.5]}\n",
      "step reward {'agent0': -2.0636072486284265, 'agent1': -4.789604962613751}\n",
      "STEP: 99\n",
      "DETERMINED ACTION: {'agent0': [0.10099000000000001, 0.5], 'agent1': [0.10099000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10099000000000001, 0.5], 'agent1': [0.10099000000000001, 0.5]}\n",
      "step reward {'agent0': -2.149608889132932, 'agent1': -4.8060481856717185}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 4\n",
      "STEP: 0\n",
      "DETERMINED ACTION: {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "step reward {'agent0': 0.0, 'agent1': 0.0}\n",
      "STEP: 1\n",
      "DETERMINED ACTION: {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "ACTION = {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "step reward {'agent0': 0.0038526555422579946, 'agent1': 0.004135040017045982}\n",
      "STEP: 2\n",
      "DETERMINED ACTION: {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "step reward {'agent0': 0.01736952331648215, 'agent1': 0.01858249846210685}\n",
      "STEP: 3\n",
      "DETERMINED ACTION: {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "step reward {'agent0': 0.031146377108932685, 'agent1': 0.03326491356415968}\n",
      "STEP: 4\n",
      "DETERMINED ACTION: {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "ACTION = {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "step reward {'agent0': 0.04440653490555097, 'agent1': 0.04752700047206012}\n",
      "STEP: 5\n",
      "DETERMINED ACTION: {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "ACTION = {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "step reward {'agent0': 0.05722315501278951, 'agent1': 0.061258810639572725}\n",
      "STEP: 6\n",
      "DETERMINED ACTION: {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "step reward {'agent0': 0.0697701561301046, 'agent1': 0.07460161797301573}\n",
      "STEP: 7\n",
      "DETERMINED ACTION: {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "ACTION = {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "step reward {'agent0': 0.08185168189329399, 'agent1': 0.08754333648014992}\n",
      "STEP: 8\n",
      "DETERMINED ACTION: {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "ACTION = {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "step reward {'agent0': 0.09352529335224245, 'agent1': 0.10008022845947041}\n",
      "STEP: 9\n",
      "DETERMINED ACTION: {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "step reward {'agent0': 0.10481378900734901, 'agent1': 0.11217525188540045}\n",
      "STEP: 10\n",
      "DETERMINED ACTION: {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1157129144535832, 'agent1': 0.12385333999079096}\n",
      "STEP: 11\n",
      "DETERMINED ACTION: {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "ACTION = {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "step reward {'agent0': 0.1262213475412153, 'agent1': 0.13511436783483488}\n",
      "STEP: 12\n",
      "DETERMINED ACTION: {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "ACTION = {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "step reward {'agent0': 0.13634121315703499, 'agent1': 0.14595952800487072}\n",
      "STEP: 13\n",
      "DETERMINED ACTION: {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "step reward {'agent0': 0.1460735712330344, 'agent1': 0.1563289763156302}\n",
      "STEP: 14\n",
      "DETERMINED ACTION: {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "ACTION = {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "step reward {'agent0': 0.15541868313394386, 'agent1': 0.1662849479755415}\n",
      "STEP: 15\n",
      "DETERMINED ACTION: {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "ACTION = {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "step reward {'agent0': 0.16437708022658917, 'agent1': 0.17579624822253034}\n",
      "STEP: 16\n",
      "DETERMINED ACTION: {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "ACTION = {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "step reward {'agent0': 0.172825888977618, 'agent1': 0.18492378080641061}\n",
      "STEP: 17\n",
      "DETERMINED ACTION: {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "step reward {'agent0': 0.18094927867844784, 'agent1': 0.1934862957290193}\n",
      "STEP: 18\n",
      "DETERMINED ACTION: {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "ACTION = {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "step reward {'agent0': 0.18862464349410019, 'agent1': 0.20178683347265308}\n",
      "STEP: 19\n",
      "DETERMINED ACTION: {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "ACTION = {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "step reward {'agent0': 0.19585277335928464, 'agent1': 0.20952260727064792}\n",
      "STEP: 20\n",
      "DETERMINED ACTION: {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20266391293275338, 'agent1': 0.21669282033876464}\n",
      "STEP: 21\n",
      "DETERMINED ACTION: {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "step reward {'agent0': 0.20905913197290127, 'agent1': 0.2235422691307034}\n",
      "STEP: 22\n",
      "DETERMINED ACTION: {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "ACTION = {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "step reward {'agent0': 0.21500709893949915, 'agent1': 0.2298567959083872}\n",
      "STEP: 23\n",
      "DETERMINED ACTION: {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "ACTION = {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "step reward {'agent0': 0.22047862820241032, 'agent1': 0.23569848587628495}\n",
      "STEP: 24\n",
      "DETERMINED ACTION: {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "step reward {'agent0': 0.22556473521857456, 'agent1': 0.24106853961641284}\n",
      "STEP: 25\n",
      "DETERMINED ACTION: {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "ACTION = {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "step reward {'agent0': 0.2301741291411029, 'agent1': 0.24590457763296747}\n",
      "STEP: 26\n",
      "DETERMINED ACTION: {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "ACTION = {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "step reward {'agent0': 0.23427707819948046, 'agent1': 0.2502379111658073}\n",
      "STEP: 27\n",
      "DETERMINED ACTION: {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2379346168747179, 'agent1': 0.254069596237227}\n",
      "STEP: 28\n",
      "DETERMINED ACTION: {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24111621721929616, 'agent1': 0.25733713266445635}\n",
      "STEP: 29\n",
      "DETERMINED ACTION: {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "ACTION = {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "step reward {'agent0': 0.24373085892856883, 'agent1': 0.26004223610238325}\n",
      "STEP: 30\n",
      "DETERMINED ACTION: {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "ACTION = {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "step reward {'agent0': 0.24590086807487066, 'agent1': 0.26221608247272005}\n",
      "STEP: 31\n",
      "DETERMINED ACTION: {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2475352144369064, 'agent1': 0.26379682596068005}\n",
      "STEP: 32\n",
      "DETERMINED ACTION: {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "ACTION = {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "step reward {'agent0': 0.24860337945049588, 'agent1': 0.26484655637077226}\n",
      "STEP: 33\n",
      "DETERMINED ACTION: {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "ACTION = {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "step reward {'agent0': 0.24913559949062025, 'agent1': 0.2651831057182559}\n",
      "STEP: 34\n",
      "DETERMINED ACTION: {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "step reward {'agent0': 0.2491024206288558, 'agent1': 0.26492785921826817}\n",
      "STEP: 35\n",
      "DETERMINED ACTION: {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "ACTION = {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "step reward {'agent0': 0.24850409257288109, 'agent1': 0.26402030454888425}\n",
      "STEP: 36\n",
      "DETERMINED ACTION: {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "ACTION = {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "step reward {'agent0': 0.24727958048560833, 'agent1': 0.2624605548971004}\n",
      "STEP: 37\n",
      "DETERMINED ACTION: {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "ACTION = {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "step reward {'agent0': -4.833882746581404, 'agent1': -4.697856588187829}\n",
      "STEP: 38\n",
      "DETERMINED ACTION: {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step reward {'agent0': 0, 'agent1': 0}\n",
      "We done\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = dict(agent0 = [0.1, 0.5], agent1=[0.1, 0.5]) # First is throttle, second is steering\n",
    "\n",
    "for episode in range(5):\n",
    "    print(f\"episode: {episode}\")\n",
    "    for i in range(2000):\n",
    "        \n",
    "        action = dict(agent0 = [0.1 + i * 1e-5, 0.5], agent1=[0.1 + i * 1e-5, 0.5])\n",
    "        \n",
    "        o, r, te, tc, info = env.step(action)\n",
    "        print(f\"terminated: {te}\")\n",
    "        print(f\"truncated: {tc}\")\n",
    "        if te or tc:\n",
    "            break\n",
    "    env.reset()\n",
    "        \n",
    "env.close()\n",
    "print(\"We done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731da071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import contextlib\n",
    "import logging\n",
    "import pathlib\n",
    "import time\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import scenic\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import tyro\n",
    "from gymnasium import spaces\n",
    "from scenic.gym import ScenicGymEnv\n",
    "from scenic.simulators.metadrive import MetaDriveSimulator\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    \"\"\"Hyperparameters and configuration for the PPO training.\"\"\"\n",
    "\n",
    "    # Environment/scenic file to use\n",
    "    scenic_file: str = \"idm.scenic\"\n",
    "    # Number of parallel processes for data collection\n",
    "    num_workers: int = 4\n",
    "    # Total timesteps for training\n",
    "    total_timesteps: int = 1_000_000\n",
    "    # Timesteps collected by each worker per iteration\n",
    "    steps_per_worker: int = 256\n",
    "    # Number of optimization epochs per PPO iteration\n",
    "    num_epochs: int = 4\n",
    "    # Size of minibatches for optimization\n",
    "    minibatch_size: int = 6\n",
    "    # Discount factor\n",
    "    gamma: float = 0.9\n",
    "    # Lambda for Generalized Advantage Estimation\n",
    "    gae_lambda: float = 0.9\n",
    "    # PPO clipping parameter\n",
    "    clip_epsilon: float = 0.2\n",
    "    # Learning rate\n",
    "    lr: float = 3e-4\n",
    "    # Entropy coefficient for exploration bonus\n",
    "    entropy_coef: float = 0.01\n",
    "    # Value function loss coefficient\n",
    "    value_loss_coef: float = 0.5\n",
    "    # Gradient clipping threshold\n",
    "    max_grad_norm: float = 0.5\n",
    "    # Random seed\n",
    "    seed: int = 4\n",
    "    # Directory to save models\n",
    "    model_dir: str = \"models\"\n",
    "\n",
    "\n",
    "LOG_STD_MAX = 2\n",
    "LOG_STD_MIN = -5\n",
    "EPSILON = 1e-5\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    \"\"\"A simple Actor-Critic network for discrete action spaces. Shares layers between actor and critic.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, action_space: spaces.Box, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.shared_layer = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.fc_mean = nn.Linear(hidden_dim, np.prod(action_space.shape))\n",
    "        self.fc_logstd = nn.Linear(hidden_dim, np.prod(action_space.shape))\n",
    "        self.critic = nn.Linear(hidden_dim, 1)  # Value head\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"action_scale\",\n",
    "            torch.tensor((action_space.high - action_space.low) / 2.0, dtype=torch.float32),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"action_bias\",\n",
    "            torch.tensor((action_space.high + action_space.low) / 2.0, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: any) -> tuple:\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        shared_features = self.shared_layer(x)\n",
    "        mean = self.fc_mean(shared_features)\n",
    "        log_std = self.fc_logstd(shared_features)\n",
    "        log_std = torch.tanh(log_std)\n",
    "        log_std = LOG_STD_MIN + 0.5 * (LOG_STD_MAX - LOG_STD_MIN) * (log_std + 1)\n",
    "        value = self.critic(shared_features)\n",
    "        return mean, log_std, value\n",
    "\n",
    "\n",
    "# %%\n",
    "def worker_fn(worker_id: int, steps_per_worker: int, model_state_dict: dict, data_queue: mp.Queue, seed: int, scenic_file: str) -> None:\n",
    "    \"\"\"Execute function for each worker process. Initializes environment and model, collects trajectories, and sends data back.\"\"\"\n",
    "    \n",
    "    logging.getLogger(__name__).debug(\"Worker %s: Initializing...\", worker_id)\n",
    "    \n",
    "    root_user = os.path.expanduser(\"~\")\n",
    "    sumo_map = root_user + \"/ScenicGym/assets/maps/CARLA/Town01.net.xml\"\n",
    "    obs_space_dict = {\"agent0\" :  gym.spaces.Box(-0.0, 1.0 , (249,), dtype=np.float32),\n",
    "                     \"agent1\": gym.spaces.Box(-0.0, 1.0 , (249,), dtype=np.float32)}\n",
    "\n",
    "    action_space_dict = {'agent0': gym.spaces.Box(-1.0, 1.0, (2,), np.float32),\n",
    "                         'agent1': gym.spaces.Box(-1.0, 1.0, (2,), np.float32)}\n",
    "    \n",
    "    scenario = scenic.scenarioFromFile(\"exp.scenic\",\n",
    "                                   model=\"scenic.simulators.metadrive.model\",\n",
    "                               mode2D=True)\n",
    "    env = ScenicZooEnv(scenario, \n",
    "                           MetaDriveSimulator(sumo_map=sumo_map, render=True, real_time=True),\n",
    "                           None, \n",
    "                           max_steps=50, \n",
    "                           observation_space = obs_space_dict, \n",
    "                           action_space = action_space_dict, \n",
    "                           agents=[\"agent0\", \"agent1\"])\n",
    "    \n",
    "    # TODO modify the code below to work with multi-agent things\n",
    "    \n",
    "    obs_space_shape = env.observation_space.shape\n",
    "    action_space = env.action_space\n",
    "    obs_dim = np.prod(obs_space_shape) if isinstance(obs_space_shape, tuple) else obs_space_shape[0]\n",
    "    worker_seed = seed + worker_id\n",
    "    env.reset(seed=worker_seed)\n",
    "\n",
    "    local_model = ActorCritic(obs_dim, action_space)\n",
    "    local_model.load_state_dict(model_state_dict)\n",
    "    local_model.eval()\n",
    "\n",
    "    observations = []\n",
    "    actions = []\n",
    "    log_probs = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    values = []\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    current_step = 0\n",
    "    while current_step < steps_per_worker:\n",
    "        obs_tensor = torch.tensor(obs.flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            mean, log_std, value = local_model(obs_tensor)\n",
    "            std = log_std.exp()\n",
    "            normal = torch.distributions.Normal(mean, std)\n",
    "            x_t = normal.rsample()\n",
    "            y_t = torch.tanh(x_t)\n",
    "            action = y_t * local_model.action_scale + local_model.action_bias\n",
    "            log_prob = normal.log_prob(x_t)\n",
    "            log_prob -= torch.log(local_model.action_scale * (1 - y_t.pow(2)) + 1e-6)\n",
    "            log_prob = log_prob.sum(1, keepdim=True)\n",
    "        action = action.cpu().numpy().squeeze(0)\n",
    "        next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        observations.append(obs.flatten())\n",
    "        actions.append(action)\n",
    "        log_probs.append(log_prob.item())\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "        values.append(value.item())\n",
    "\n",
    "        obs = next_obs\n",
    "        current_step += 1\n",
    "\n",
    "        if done:\n",
    "            obs, _ = env.reset()\n",
    "\n",
    "    last_obs_tensor = torch.tensor(obs.flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        _, _, last_value = local_model(last_obs_tensor)\n",
    "        last_value = last_value.item()\n",
    "\n",
    "    trajectory_data = {\n",
    "        \"observations\": np.array(observations, dtype=np.float32),\n",
    "        \"actions\": np.array(actions, dtype=np.float32),\n",
    "        \"log_probs\": np.array(log_probs, dtype=np.float32),\n",
    "        \"rewards\": np.array(rewards, dtype=np.float32),\n",
    "        \"dones\": np.array(dones, dtype=np.bool_),\n",
    "        \"values\": np.array(values, dtype=np.float32),\n",
    "        \"last_value\": last_value,\n",
    "        \"last_done\": done,\n",
    "    }\n",
    "\n",
    "    data_queue.put(trajectory_data)\n",
    "    logging.getLogger(__name__).debug(\"Worker %s: Finished collecting %s steps.\", worker_id, current_step)\n",
    "    env.close()\n",
    "\n",
    "\n",
    "# %%\n",
    "def compute_gae(\n",
    "    rewards: np.array,\n",
    "    values: np.array,\n",
    "    dones: np.array,\n",
    "    last_value: float,\n",
    "    last_done: float,\n",
    "    gamma: float,\n",
    "    gae_lambda: float,\n",
    ") -> tuple:\n",
    "    \"\"\"Compute Generalized Advantage Estimation (GAE).\"\"\"\n",
    "    advantages = np.zeros_like(rewards)\n",
    "    last_gae_lam = 0\n",
    "    num_steps = len(rewards)\n",
    "    next_values = np.append(values[1:], last_value if not last_done else 0.0)\n",
    "    next_non_terminal = 1.0 - dones\n",
    "    deltas = rewards + gamma * next_values * next_non_terminal - values\n",
    "\n",
    "    for t in reversed(range(num_steps)):\n",
    "        last_gae_lam = deltas[t] + gamma * gae_lambda * next_non_terminal[t] * last_gae_lam\n",
    "        advantages[t] = last_gae_lam\n",
    "\n",
    "    returns = advantages + values\n",
    "    return advantages, returns\n",
    "\n",
    "\n",
    "# %%\n",
    "def ppo_update(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    batch_obs: torch.Tensor,\n",
    "    batch_actions: torch.Tensor,\n",
    "    batch_log_probs_old: torch.Tensor,\n",
    "    batch_advantages: torch.Tensor,\n",
    "    batch_returns: torch.Tensor,\n",
    "    num_epochs: int,\n",
    "    minibatch_size: int,\n",
    "    clip_epsilon: float,\n",
    "    entropy_coef: float,\n",
    "    value_loss_coef: float,\n",
    "    max_grad_norm: float,\n",
    "    rng: np.random.Generator,\n",
    ") -> None:\n",
    "    \"\"\"Perform the PPO update step using collected batch data.\"\"\"\n",
    "    batch_size = batch_obs.size(0)\n",
    "    batch_advantages = (batch_advantages - batch_advantages.mean()) / (batch_advantages.std() + 1e-8)\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        indices = rng.permutation(batch_size)\n",
    "        for start in range(0, batch_size, minibatch_size):\n",
    "            end = start + minibatch_size\n",
    "            minibatch_indices = indices[start:end]\n",
    "\n",
    "            mb_obs = batch_obs[minibatch_indices]\n",
    "            mb_actions = batch_actions[minibatch_indices]\n",
    "            mb_log_probs_old = batch_log_probs_old[minibatch_indices]\n",
    "            mb_advantages = batch_advantages[minibatch_indices]\n",
    "            mb_returns = batch_returns[minibatch_indices]\n",
    "\n",
    "            mean, log_std, values_pred = model(mb_obs)\n",
    "            std = log_std.exp()\n",
    "            normal = torch.distributions.Normal(mean, std)\n",
    "\n",
    "            mb_actions_clamped = torch.clamp(mb_actions, -1.0 + EPSILON, 1.0 - EPSILON)\n",
    "            unsquashed_mb_actions = torch.atanh(mb_actions_clamped)\n",
    "            log_probs_gaussian = normal.log_prob(unsquashed_mb_actions).sum(dim=-1)\n",
    "            log_prob_squash_correction = torch.log(1.0 - mb_actions.pow(2) + EPSILON).sum(dim=-1)\n",
    "            log_probs_new = log_probs_gaussian - log_prob_squash_correction\n",
    "\n",
    "            entropy = normal.entropy().mean()\n",
    "            values_pred = values_pred.squeeze(-1)\n",
    "\n",
    "            prob_ratio = torch.exp(log_probs_new - mb_log_probs_old)\n",
    "            surr1 = prob_ratio * mb_advantages\n",
    "            surr2 = torch.clamp(prob_ratio, 1.0 - clip_epsilon, 1.0 + clip_epsilon) * mb_advantages\n",
    "            policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "            value_loss = 0.5 * ((values_pred - mb_returns) ** 2).mean()\n",
    "\n",
    "            loss = policy_loss + value_loss_coef * value_loss - entropy_coef * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Run the PPO training.\"\"\"\n",
    "    args = tyro.cli(Args)\n",
    "\n",
    "    # Ensure model directory exists\n",
    "    if not pathlib.Path.exists(pathlib.Path(args.model_dir)):\n",
    "        pathlib.Path.mkdir(pathlib.Path(args.model_dir))\n",
    "    print(\"Model directory:\", args.model_dir)\n",
    "\n",
    "    # Set the environment name based on the scenic file\n",
    "    env_name = pathlib.Path(args.scenic_file).stem\n",
    "\n",
    "    # Set up multiprocess start method\n",
    "    with contextlib.suppress(RuntimeError):\n",
    "        mp.set_start_method(\"spawn\")\n",
    "\n",
    "    # seeds\n",
    "    rng = np.random.default_rng(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    logger.info(\"Starting PPO training...\")\n",
    "    logger.info(\"Environment: %s, Workers: %s, Total Timesteps: %s\", env_name, args.num_workers, args.total_timesteps)\n",
    "    logger.info(\"Hyperparameters: gamma=%s, lambda=%s, clip_eps=%s, lr=%s\", args.gamma, args.gae_lambda, args.clip_epsilon, args.lr)\n",
    "\n",
    "    # temp env to get obs and action space\n",
    "    env = ScenicGymEnv(\n",
    "        env_name,\n",
    "        MetaDriveSimulator(timestep=0.05, sumo_map=pathlib.Path(\"../maps/Town06.net.xml\"), render=False, real_time=False),\n",
    "        observation_space=spaces.Box(low=-np.inf, high=np.inf, shape=(5, 7)),\n",
    "        action_space=spaces.Box(low=-1, high=1, shape=(2,)),\n",
    "        max_steps=700,\n",
    "    )\n",
    "    obs_space_shape = env.observation_space.shape\n",
    "    action_space = env.action_space\n",
    "    obs_dim = np.prod(obs_space_shape) if isinstance(obs_space_shape, tuple) else obs_space_shape[0]\n",
    "    env.close()\n",
    "\n",
    "    model = ActorCritic(obs_dim, action_space).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    batch_size = args.num_workers * args.steps_per_worker\n",
    "    num_updates = args.total_timesteps // batch_size\n",
    "    logger.info(\"Batch Size (Workers * Steps): %s\", batch_size)\n",
    "    logger.info(\"Total PPO Updates: %s\", num_updates)\n",
    "\n",
    "    data_queue = mp.Queue()\n",
    "\n",
    "    total_steps = 0\n",
    "    start_time = time.time()\n",
    "    episode_rewards = deque(maxlen=100)\n",
    "    episode_lengths = deque(maxlen=100)\n",
    "    total_episodes = 0\n",
    "\n",
    "    # Training Loop\n",
    "    for update in range(1, num_updates + 1):\n",
    "        update_start_time = time.time()\n",
    "        model.eval()\n",
    "\n",
    "        processes = []\n",
    "        current_model_state_dict = model.state_dict()\n",
    "        for i in range(args.num_workers):\n",
    "            p = mp.Process(\n",
    "                target=worker_fn,\n",
    "                args=(\n",
    "                    i,\n",
    "                    args.steps_per_worker,\n",
    "                    current_model_state_dict,\n",
    "                    data_queue,\n",
    "                    args.seed + update * args.num_workers,\n",
    "                    args.scenic_file,\n",
    "                ),\n",
    "            )\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "\n",
    "        all_trajectory_data = [data_queue.get() for _ in range(args.num_workers)]\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "        logger.debug(\"Update %s: All workers finished.\", update)\n",
    "\n",
    "        batch_obs_list = []\n",
    "        batch_actions_list = []\n",
    "        batch_log_probs_list = []\n",
    "        batch_advantages_list = []\n",
    "        batch_returns_list = []\n",
    "\n",
    "        for data in all_trajectory_data:\n",
    "            advantages, returns = compute_gae(\n",
    "                data[\"rewards\"],\n",
    "                data[\"values\"],\n",
    "                data[\"dones\"],\n",
    "                data[\"last_value\"],\n",
    "                data[\"last_done\"],\n",
    "                args.gamma,\n",
    "                args.gae_lambda,\n",
    "            )\n",
    "            batch_advantages_list.append(advantages)\n",
    "            batch_returns_list.append(returns)\n",
    "            batch_obs_list.append(data[\"observations\"])\n",
    "            batch_actions_list.append(data[\"actions\"])\n",
    "            batch_log_probs_list.append(data[\"log_probs\"])\n",
    "\n",
    "            current_episode_reward = 0\n",
    "            current_episode_length = 0\n",
    "            for reward, done in zip(data[\"rewards\"], data[\"dones\"], strict=False):\n",
    "                current_episode_reward += reward\n",
    "                current_episode_length += 1\n",
    "                if done:\n",
    "                    episode_rewards.append(current_episode_reward)\n",
    "                    episode_lengths.append(current_episode_length)\n",
    "                    total_episodes += 1\n",
    "                    current_episode_reward = 0\n",
    "                    current_episode_length = 0\n",
    "\n",
    "        batch_obs = torch.tensor(np.concatenate(batch_obs_list), dtype=torch.float32).to(device)\n",
    "        batch_actions = torch.tensor(np.concatenate(batch_actions_list), dtype=torch.float32).to(device)\n",
    "        batch_log_probs_old = torch.tensor(np.concatenate(batch_log_probs_list), dtype=torch.float32).to(device)\n",
    "        batch_advantages = torch.tensor(np.concatenate(batch_advantages_list), dtype=torch.float32).to(device)\n",
    "        batch_returns = torch.tensor(np.concatenate(batch_returns_list), dtype=torch.float32).to(device)\n",
    "\n",
    "        model.train()\n",
    "        ppo_update(\n",
    "            model,\n",
    "            optimizer,\n",
    "            batch_obs,\n",
    "            batch_actions,\n",
    "            batch_log_probs_old,\n",
    "            batch_advantages,\n",
    "            batch_returns,\n",
    "            args.num_epochs,\n",
    "            args.minibatch_size,\n",
    "            args.clip_epsilon,\n",
    "            args.entropy_coef,\n",
    "            args.value_loss_coef,\n",
    "            args.max_grad_norm,\n",
    "            rng,\n",
    "        )\n",
    "\n",
    "        total_steps += batch_size\n",
    "        update_end_time = time.time()\n",
    "        fps = int(batch_size / (update_end_time - update_start_time))\n",
    "        avg_reward = np.mean(episode_rewards) if episode_rewards else 0\n",
    "        avg_length = np.mean(episode_lengths) if episode_lengths else 0\n",
    "\n",
    "        if update % 1 == 0 or update == 1:\n",
    "            logger.info(\n",
    "                \"Update: %s/%s, Timesteps: %s/%s, FPS: %s, Episodes: %s, Avg Reward (Last 100): %.2f, Avg Length (Last 100): %.2f\",\n",
    "                update,\n",
    "                num_updates,\n",
    "                total_steps,\n",
    "                args.total_timesteps,\n",
    "                fps,\n",
    "                total_episodes,\n",
    "                avg_reward,\n",
    "                avg_length,\n",
    "            )\n",
    "            # Save model every 10 updates\n",
    "            torch.save(model.state_dict(), f\"{args.model_dir}/ppo_{env_name}_model.pth\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    logger.info(\"Training finished in %.2f seconds.\", end_time - start_time)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{args.model_dir}/ppo_{env_name}_model.pth\")\n",
    "    logger.info(\"Model saved to ppo_%s_model.pth\", env_name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a8049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af408e84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train(create_env, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03161f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796a7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_random_seed(0)\n",
    "# train_env=DummyVecEnv([partial(create_env, True) for _ in range(4)])\n",
    "# model = PPO(\"MlpPolicy\", \n",
    "#             train_env,\n",
    "#             n_steps=4096,\n",
    "#             verbose=1)\n",
    "\n",
    "# model.learn(total_timesteps=1000)\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fdeecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d74f2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "We done\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = dict(agent0 = [0.1, 0.5], agent1=[0.1, 0.5]) # First is throttle, second is steering\n",
    "for _ in range(2000):\n",
    "    o, r, te, tc, info = env.step(action)\n",
    "    if te or tc:\n",
    "        break\n",
    "        \n",
    "env.close()\n",
    "print(\"We done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
