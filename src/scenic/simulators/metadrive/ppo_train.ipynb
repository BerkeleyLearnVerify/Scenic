{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931f5618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kxu/ScenicGym/src/scenic/core/errors.py:271: UserWarning: unable to install sys.excepthook to format Scenic backtraces\n",
      "  warnings.warn(\"unable to install sys.excepthook to format Scenic backtraces\")\n"
     ]
    }
   ],
   "source": [
    "from scenic.zoo import ScenicZooEnv\n",
    "from scenic.simulators.metadrive import MetaDriveSimulator\n",
    "import scenic\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.ppo import MlpPolicy\n",
    "# from stable_baselines3.common.monitor import Monitor\n",
    "# from stable_baselines3.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# from stable_baselines3.common.utils import set_random_seed\n",
    "# import supersuit as ss\n",
    "import os\n",
    "\n",
    "\n",
    "# %%\n",
    "import contextlib\n",
    "import logging\n",
    "import pathlib\n",
    "import time\n",
    "# from collections import deque\n",
    "# from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import tyro\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14aee22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_user = os.path.expanduser(\"~\")\n",
    "root_user\n",
    "\n",
    "with contextlib.suppress(RuntimeError):\n",
    "        mp.set_start_method(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca76cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumo_map = root_user + \"/ScenicGym/assets/maps/CARLA/Town04.net.xml\"\n",
    "obs_space_dict = {\"agent0\" :  gym.spaces.Box(-0.0, 1.0 , (249,), dtype=np.float32),\n",
    "                 \"agent1\": gym.spaces.Box(-0.0, 1.0 , (249,), dtype=np.float32)}\n",
    "\n",
    "action_space_dict = {'agent0': gym.spaces.Box(-1.0, 1.0, (2,), np.float32),\n",
    "                     'agent1': gym.spaces.Box(-1.0, 1.0, (2,), np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0ff89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_and_rt = False\n",
    "\n",
    "scenario = scenic.scenarioFromFile(\"exp.scenic\",\n",
    "                               model=\"scenic.simulators.metadrive.model\",\n",
    "                           mode2D=True)\n",
    "env = ScenicZooEnv(scenario, \n",
    "                       MetaDriveSimulator(sumo_map=sumo_map, render=render_and_real_time, real_time=render_and_real_time),\n",
    "                       None, \n",
    "                       max_steps=100, \n",
    "                       observation_space = obs_space_dict, \n",
    "                       action_space = action_space_dict, \n",
    "                       agents=[\"agent0\", \"agent1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1988e2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10039000000000001, 0.5], 'agent1': [0.10039000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1004, 0.5], 'agent1': [0.1004, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10041, 0.5], 'agent1': [0.10041, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10042000000000001, 0.5], 'agent1': [0.10042000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10043, 0.5], 'agent1': [0.10043, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10044, 0.5], 'agent1': [0.10044, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10045000000000001, 0.5], 'agent1': [0.10045000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10046000000000001, 0.5], 'agent1': [0.10046000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10047, 0.5], 'agent1': [0.10047, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10048, 0.5], 'agent1': [0.10048, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10049000000000001, 0.5], 'agent1': [0.10049000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1005, 0.5], 'agent1': [0.1005, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10051, 0.5], 'agent1': [0.10051, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10052000000000001, 0.5], 'agent1': [0.10052000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10053000000000001, 0.5], 'agent1': [0.10053000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10054, 0.5], 'agent1': [0.10054, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10055, 0.5], 'agent1': [0.10055, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10056000000000001, 0.5], 'agent1': [0.10056000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10057, 0.5], 'agent1': [0.10057, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10058, 0.5], 'agent1': [0.10058, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10059, 0.5], 'agent1': [0.10059, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10060000000000001, 0.5], 'agent1': [0.10060000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10061, 0.5], 'agent1': [0.10061, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10062, 0.5], 'agent1': [0.10062, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10063000000000001, 0.5], 'agent1': [0.10063000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10064000000000001, 0.5], 'agent1': [0.10064000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10065, 0.5], 'agent1': [0.10065, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10066, 0.5], 'agent1': [0.10066, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10067000000000001, 0.5], 'agent1': [0.10067000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10068, 0.5], 'agent1': [0.10068, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10069, 0.5], 'agent1': [0.10069, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10070000000000001, 0.5], 'agent1': [0.10070000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10071000000000001, 0.5], 'agent1': [0.10071000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10072, 0.5], 'agent1': [0.10072, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10073, 0.5], 'agent1': [0.10073, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10074000000000001, 0.5], 'agent1': [0.10074000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10075, 0.5], 'agent1': [0.10075, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10076, 0.5], 'agent1': [0.10076, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10077000000000001, 0.5], 'agent1': [0.10077000000000001, 0.5]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10078000000000001, 0.5], 'agent1': [0.10078000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10079, 0.5], 'agent1': [0.10079, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1008, 0.5], 'agent1': [0.1008, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10081000000000001, 0.5], 'agent1': [0.10081000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10082, 0.5], 'agent1': [0.10082, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10083, 0.5], 'agent1': [0.10083, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10084, 0.5], 'agent1': [0.10084, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10085000000000001, 0.5], 'agent1': [0.10085000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10086, 0.5], 'agent1': [0.10086, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10087, 0.5], 'agent1': [0.10087, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10088000000000001, 0.5], 'agent1': [0.10088000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10089000000000001, 0.5], 'agent1': [0.10089000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1009, 0.5], 'agent1': [0.1009, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10091, 0.5], 'agent1': [0.10091, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10092000000000001, 0.5], 'agent1': [0.10092000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10093, 0.5], 'agent1': [0.10093, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10094, 0.5], 'agent1': [0.10094, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10095000000000001, 0.5], 'agent1': [0.10095000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10096000000000001, 0.5], 'agent1': [0.10096000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10097, 0.5], 'agent1': [0.10097, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10098, 0.5], 'agent1': [0.10098, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10099000000000001, 0.5], 'agent1': [0.10099000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: True\n",
      "episode: 1\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "terminated: True\n",
      "truncated: False\n",
      "episode: 2\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10039000000000001, 0.5], 'agent1': [0.10039000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1004, 0.5], 'agent1': [0.1004, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10041, 0.5], 'agent1': [0.10041, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10042000000000001, 0.5], 'agent1': [0.10042000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10043, 0.5], 'agent1': [0.10043, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10044, 0.5], 'agent1': [0.10044, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10045000000000001, 0.5], 'agent1': [0.10045000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10046000000000001, 0.5], 'agent1': [0.10046000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10047, 0.5], 'agent1': [0.10047, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10048, 0.5], 'agent1': [0.10048, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10049000000000001, 0.5], 'agent1': [0.10049000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1005, 0.5], 'agent1': [0.1005, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10051, 0.5], 'agent1': [0.10051, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10052000000000001, 0.5], 'agent1': [0.10052000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10053000000000001, 0.5], 'agent1': [0.10053000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10054, 0.5], 'agent1': [0.10054, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10055, 0.5], 'agent1': [0.10055, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10056000000000001, 0.5], 'agent1': [0.10056000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10057, 0.5], 'agent1': [0.10057, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10058, 0.5], 'agent1': [0.10058, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10059, 0.5], 'agent1': [0.10059, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10060000000000001, 0.5], 'agent1': [0.10060000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10061, 0.5], 'agent1': [0.10061, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10062, 0.5], 'agent1': [0.10062, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10063000000000001, 0.5], 'agent1': [0.10063000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10064000000000001, 0.5], 'agent1': [0.10064000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10065, 0.5], 'agent1': [0.10065, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10066, 0.5], 'agent1': [0.10066, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10067000000000001, 0.5], 'agent1': [0.10067000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10068, 0.5], 'agent1': [0.10068, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10069, 0.5], 'agent1': [0.10069, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10070000000000001, 0.5], 'agent1': [0.10070000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10071000000000001, 0.5], 'agent1': [0.10071000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10072, 0.5], 'agent1': [0.10072, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10073, 0.5], 'agent1': [0.10073, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10074000000000001, 0.5], 'agent1': [0.10074000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10075, 0.5], 'agent1': [0.10075, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10076, 0.5], 'agent1': [0.10076, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10077000000000001, 0.5], 'agent1': [0.10077000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10078000000000001, 0.5], 'agent1': [0.10078000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10079, 0.5], 'agent1': [0.10079, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1008, 0.5], 'agent1': [0.1008, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10081000000000001, 0.5], 'agent1': [0.10081000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10082, 0.5], 'agent1': [0.10082, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10083, 0.5], 'agent1': [0.10083, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10084, 0.5], 'agent1': [0.10084, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10085000000000001, 0.5], 'agent1': [0.10085000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10086, 0.5], 'agent1': [0.10086, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10087, 0.5], 'agent1': [0.10087, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10088000000000001, 0.5], 'agent1': [0.10088000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10089000000000001, 0.5], 'agent1': [0.10089000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1009, 0.5], 'agent1': [0.1009, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10091, 0.5], 'agent1': [0.10091, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10092000000000001, 0.5], 'agent1': [0.10092000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10093, 0.5], 'agent1': [0.10093, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10094, 0.5], 'agent1': [0.10094, 0.5]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10095000000000001, 0.5], 'agent1': [0.10095000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10096000000000001, 0.5], 'agent1': [0.10096000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10097, 0.5], 'agent1': [0.10097, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10098, 0.5], 'agent1': [0.10098, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10099000000000001, 0.5], 'agent1': [0.10099000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: True\n",
      "episode: 3\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10038000000000001, 0.5], 'agent1': [0.10038000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10039000000000001, 0.5], 'agent1': [0.10039000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1004, 0.5], 'agent1': [0.1004, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10041, 0.5], 'agent1': [0.10041, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10042000000000001, 0.5], 'agent1': [0.10042000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10043, 0.5], 'agent1': [0.10043, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10044, 0.5], 'agent1': [0.10044, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10045000000000001, 0.5], 'agent1': [0.10045000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10046000000000001, 0.5], 'agent1': [0.10046000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10047, 0.5], 'agent1': [0.10047, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10048, 0.5], 'agent1': [0.10048, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10049000000000001, 0.5], 'agent1': [0.10049000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1005, 0.5], 'agent1': [0.1005, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10051, 0.5], 'agent1': [0.10051, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10052000000000001, 0.5], 'agent1': [0.10052000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10053000000000001, 0.5], 'agent1': [0.10053000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10054, 0.5], 'agent1': [0.10054, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10055, 0.5], 'agent1': [0.10055, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10056000000000001, 0.5], 'agent1': [0.10056000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10057, 0.5], 'agent1': [0.10057, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10058, 0.5], 'agent1': [0.10058, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10059, 0.5], 'agent1': [0.10059, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10060000000000001, 0.5], 'agent1': [0.10060000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10061, 0.5], 'agent1': [0.10061, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10062, 0.5], 'agent1': [0.10062, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10063000000000001, 0.5], 'agent1': [0.10063000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10064000000000001, 0.5], 'agent1': [0.10064000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10065, 0.5], 'agent1': [0.10065, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10066, 0.5], 'agent1': [0.10066, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10067000000000001, 0.5], 'agent1': [0.10067000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10068, 0.5], 'agent1': [0.10068, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10069, 0.5], 'agent1': [0.10069, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10070000000000001, 0.5], 'agent1': [0.10070000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10071000000000001, 0.5], 'agent1': [0.10071000000000001, 0.5]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10072, 0.5], 'agent1': [0.10072, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10073, 0.5], 'agent1': [0.10073, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10074000000000001, 0.5], 'agent1': [0.10074000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10075, 0.5], 'agent1': [0.10075, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10076, 0.5], 'agent1': [0.10076, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10077000000000001, 0.5], 'agent1': [0.10077000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10078000000000001, 0.5], 'agent1': [0.10078000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10079, 0.5], 'agent1': [0.10079, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1008, 0.5], 'agent1': [0.1008, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10081000000000001, 0.5], 'agent1': [0.10081000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10082, 0.5], 'agent1': [0.10082, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10083, 0.5], 'agent1': [0.10083, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10084, 0.5], 'agent1': [0.10084, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10085000000000001, 0.5], 'agent1': [0.10085000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10086, 0.5], 'agent1': [0.10086, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10087, 0.5], 'agent1': [0.10087, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10088000000000001, 0.5], 'agent1': [0.10088000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10089000000000001, 0.5], 'agent1': [0.10089000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1009, 0.5], 'agent1': [0.1009, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10091, 0.5], 'agent1': [0.10091, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10092000000000001, 0.5], 'agent1': [0.10092000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10093, 0.5], 'agent1': [0.10093, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10094, 0.5], 'agent1': [0.10094, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10095000000000001, 0.5], 'agent1': [0.10095000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10096000000000001, 0.5], 'agent1': [0.10096000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10097, 0.5], 'agent1': [0.10097, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10098, 0.5], 'agent1': [0.10098, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10099000000000001, 0.5], 'agent1': [0.10099000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: True\n",
      "episode: 4\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10001, 0.5], 'agent1': [0.10001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10002000000000001, 0.5], 'agent1': [0.10002000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10003000000000001, 0.5], 'agent1': [0.10003000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10004, 0.5], 'agent1': [0.10004, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10005, 0.5], 'agent1': [0.10005, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10006000000000001, 0.5], 'agent1': [0.10006000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10007, 0.5], 'agent1': [0.10007, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10008, 0.5], 'agent1': [0.10008, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10009000000000001, 0.5], 'agent1': [0.10009000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10010000000000001, 0.5], 'agent1': [0.10010000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10011, 0.5], 'agent1': [0.10011, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10012, 0.5], 'agent1': [0.10012, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10013000000000001, 0.5], 'agent1': [0.10013000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10014, 0.5], 'agent1': [0.10014, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10015, 0.5], 'agent1': [0.10015, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10016, 0.5], 'agent1': [0.10016, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10017000000000001, 0.5], 'agent1': [0.10017000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10018, 0.5], 'agent1': [0.10018, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10019, 0.5], 'agent1': [0.10019, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10020000000000001, 0.5], 'agent1': [0.10020000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10021000000000001, 0.5], 'agent1': [0.10021000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10022, 0.5], 'agent1': [0.10022, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10023, 0.5], 'agent1': [0.10023, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10024000000000001, 0.5], 'agent1': [0.10024000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10025, 0.5], 'agent1': [0.10025, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10026, 0.5], 'agent1': [0.10026, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10027000000000001, 0.5], 'agent1': [0.10027000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10028000000000001, 0.5], 'agent1': [0.10028000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10029, 0.5], 'agent1': [0.10029, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.1003, 0.5], 'agent1': [0.1003, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10031000000000001, 0.5], 'agent1': [0.10031000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10032, 0.5], 'agent1': [0.10032, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10033, 0.5], 'agent1': [0.10033, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10034000000000001, 0.5], 'agent1': [0.10034000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10035000000000001, 0.5], 'agent1': [0.10035000000000001, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10036, 0.5], 'agent1': [0.10036, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "ACTION = {'agent0': [0.10037, 0.5], 'agent1': [0.10037, 0.5]}\n",
      "terminated: False\n",
      "truncated: False\n",
      "terminated: True\n",
      "truncated: False\n",
      "We done\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = dict(agent0 = [0.1, 0.5], agent1=[0.1, 0.5]) # First is throttle, second is steering\n",
    "\n",
    "for episode in range(5):\n",
    "    print(f\"episode: {episode}\")\n",
    "    for i in range(2000):\n",
    "        \n",
    "        action = dict(agent0 = [0.1 + i * 1e-5, 0.5], agent1=[0.1 + i * 1e-5, 0.5])\n",
    "        \n",
    "        o, r, te, tc, info = env.step(action)\n",
    "        \n",
    "        if te or tc:\n",
    "            print(f\"RECEIVED LAST REWARD: {r}\")\n",
    "            break\n",
    "    env.reset()\n",
    "        \n",
    "env.close()\n",
    "print(\"We done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731da071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import contextlib\n",
    "import logging\n",
    "import pathlib\n",
    "import time\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import scenic\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import tyro\n",
    "from gymnasium import spaces\n",
    "from scenic.gym import ScenicGymEnv\n",
    "from scenic.simulators.metadrive import MetaDriveSimulator\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    \"\"\"Hyperparameters and configuration for the PPO training.\"\"\"\n",
    "\n",
    "    # Environment/scenic file to use\n",
    "    scenic_file: str = \"idm.scenic\"\n",
    "    # Number of parallel processes for data collection\n",
    "    num_workers: int = 4\n",
    "    # Total timesteps for training\n",
    "    total_timesteps: int = 1_000_000\n",
    "    # Timesteps collected by each worker per iteration\n",
    "    steps_per_worker: int = 256\n",
    "    # Number of optimization epochs per PPO iteration\n",
    "    num_epochs: int = 4\n",
    "    # Size of minibatches for optimization\n",
    "    minibatch_size: int = 6\n",
    "    # Discount factor\n",
    "    gamma: float = 0.9\n",
    "    # Lambda for Generalized Advantage Estimation\n",
    "    gae_lambda: float = 0.9\n",
    "    # PPO clipping parameter\n",
    "    clip_epsilon: float = 0.2\n",
    "    # Learning rate\n",
    "    lr: float = 3e-4\n",
    "    # Entropy coefficient for exploration bonus\n",
    "    entropy_coef: float = 0.01\n",
    "    # Value function loss coefficient\n",
    "    value_loss_coef: float = 0.5\n",
    "    # Gradient clipping threshold\n",
    "    max_grad_norm: float = 0.5\n",
    "    # Random seed\n",
    "    seed: int = 4\n",
    "    # Directory to save models\n",
    "    model_dir: str = \"models\"\n",
    "\n",
    "\n",
    "LOG_STD_MAX = 2\n",
    "LOG_STD_MIN = -5\n",
    "EPSILON = 1e-5\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    \"\"\"A simple Actor-Critic network for discrete action spaces. Shares layers between actor and critic.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, action_space: spaces.Box, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.shared_layer = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.fc_mean = nn.Linear(hidden_dim, np.prod(action_space.shape))\n",
    "        self.fc_logstd = nn.Linear(hidden_dim, np.prod(action_space.shape))\n",
    "        self.critic = nn.Linear(hidden_dim, 1)  # Value head\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"action_scale\",\n",
    "            torch.tensor((action_space.high - action_space.low) / 2.0, dtype=torch.float32),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"action_bias\",\n",
    "            torch.tensor((action_space.high + action_space.low) / 2.0, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: any) -> tuple:\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        shared_features = self.shared_layer(x)\n",
    "        mean = self.fc_mean(shared_features)\n",
    "        log_std = self.fc_logstd(shared_features)\n",
    "        log_std = torch.tanh(log_std)\n",
    "        log_std = LOG_STD_MIN + 0.5 * (LOG_STD_MAX - LOG_STD_MIN) * (log_std + 1)\n",
    "        value = self.critic(shared_features)\n",
    "        return mean, log_std, value\n",
    "\n",
    "\n",
    "# %%\n",
    "def worker_fn(worker_id: int, steps_per_worker: int, model_state_dict: dict, data_queue: mp.Queue, seed: int, scenic_file: str) -> None:\n",
    "    \"\"\"Execute function for each worker process. Initializes environment and model, collects trajectories, and sends data back.\"\"\"\n",
    "    \n",
    "    logging.getLogger(__name__).debug(\"Worker %s: Initializing...\", worker_id)\n",
    "    \n",
    "    root_user = os.path.expanduser(\"~\")\n",
    "    sumo_map = root_user + \"/ScenicGym/assets/maps/CARLA/Town01.net.xml\"\n",
    "    obs_space_dict = {\"agent0\" :  gym.spaces.Box(-0.0, 1.0 , (249,), dtype=np.float32),\n",
    "                     \"agent1\": gym.spaces.Box(-0.0, 1.0 , (249,), dtype=np.float32)}\n",
    "\n",
    "    action_space_dict = {'agent0': gym.spaces.Box(-1.0, 1.0, (2,), np.float32),\n",
    "                         'agent1': gym.spaces.Box(-1.0, 1.0, (2,), np.float32)}\n",
    "    \n",
    "    scenario = scenic.scenarioFromFile(\"exp.scenic\",\n",
    "                                   model=\"scenic.simulators.metadrive.model\",\n",
    "                               mode2D=True)\n",
    "    env = ScenicZooEnv(scenario, \n",
    "                           MetaDriveSimulator(sumo_map=sumo_map, render=True, real_time=True),\n",
    "                           None, \n",
    "                           max_steps=50, \n",
    "                           observation_space = obs_space_dict, \n",
    "                           action_space = action_space_dict, \n",
    "                           agents=[\"agent0\", \"agent1\"])\n",
    "    \n",
    "    # TODO modify the code below to work with multi-agent things\n",
    "    \n",
    "    obs_space_shape = env.observation_space.shape\n",
    "    action_space = env.action_space\n",
    "    obs_dim = np.prod(obs_space_shape) if isinstance(obs_space_shape, tuple) else obs_space_shape[0]\n",
    "    worker_seed = seed + worker_id\n",
    "    env.reset(seed=worker_seed)\n",
    "\n",
    "    local_model = ActorCritic(obs_dim, action_space)\n",
    "    local_model.load_state_dict(model_state_dict)\n",
    "    local_model.eval()\n",
    "\n",
    "    observations = []\n",
    "    actions = []\n",
    "    log_probs = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    values = []\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    current_step = 0\n",
    "    while current_step < steps_per_worker:\n",
    "        obs_tensor = torch.tensor(obs.flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            mean, log_std, value = local_model(obs_tensor)\n",
    "            std = log_std.exp()\n",
    "            normal = torch.distributions.Normal(mean, std)\n",
    "            x_t = normal.rsample()\n",
    "            y_t = torch.tanh(x_t)\n",
    "            action = y_t * local_model.action_scale + local_model.action_bias\n",
    "            log_prob = normal.log_prob(x_t)\n",
    "            log_prob -= torch.log(local_model.action_scale * (1 - y_t.pow(2)) + 1e-6)\n",
    "            log_prob = log_prob.sum(1, keepdim=True)\n",
    "        action = action.cpu().numpy().squeeze(0)\n",
    "        next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        observations.append(obs.flatten())\n",
    "        actions.append(action)\n",
    "        log_probs.append(log_prob.item())\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "        values.append(value.item())\n",
    "\n",
    "        obs = next_obs\n",
    "        current_step += 1\n",
    "\n",
    "        if done:\n",
    "            obs, _ = env.reset()\n",
    "\n",
    "    last_obs_tensor = torch.tensor(obs.flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        _, _, last_value = local_model(last_obs_tensor)\n",
    "        last_value = last_value.item()\n",
    "\n",
    "    trajectory_data = {\n",
    "        \"observations\": np.array(observations, dtype=np.float32),\n",
    "        \"actions\": np.array(actions, dtype=np.float32),\n",
    "        \"log_probs\": np.array(log_probs, dtype=np.float32),\n",
    "        \"rewards\": np.array(rewards, dtype=np.float32),\n",
    "        \"dones\": np.array(dones, dtype=np.bool_),\n",
    "        \"values\": np.array(values, dtype=np.float32),\n",
    "        \"last_value\": last_value,\n",
    "        \"last_done\": done,\n",
    "    }\n",
    "\n",
    "    data_queue.put(trajectory_data)\n",
    "    logging.getLogger(__name__).debug(\"Worker %s: Finished collecting %s steps.\", worker_id, current_step)\n",
    "    env.close()\n",
    "\n",
    "\n",
    "# %%\n",
    "def compute_gae(\n",
    "    rewards: np.array,\n",
    "    values: np.array,\n",
    "    dones: np.array,\n",
    "    last_value: float,\n",
    "    last_done: float,\n",
    "    gamma: float,\n",
    "    gae_lambda: float,\n",
    ") -> tuple:\n",
    "    \"\"\"Compute Generalized Advantage Estimation (GAE).\"\"\"\n",
    "    advantages = np.zeros_like(rewards)\n",
    "    last_gae_lam = 0\n",
    "    num_steps = len(rewards)\n",
    "    next_values = np.append(values[1:], last_value if not last_done else 0.0)\n",
    "    next_non_terminal = 1.0 - dones\n",
    "    deltas = rewards + gamma * next_values * next_non_terminal - values\n",
    "\n",
    "    for t in reversed(range(num_steps)):\n",
    "        last_gae_lam = deltas[t] + gamma * gae_lambda * next_non_terminal[t] * last_gae_lam\n",
    "        advantages[t] = last_gae_lam\n",
    "\n",
    "    returns = advantages + values\n",
    "    return advantages, returns\n",
    "\n",
    "\n",
    "# %%\n",
    "def ppo_update(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    batch_obs: torch.Tensor,\n",
    "    batch_actions: torch.Tensor,\n",
    "    batch_log_probs_old: torch.Tensor,\n",
    "    batch_advantages: torch.Tensor,\n",
    "    batch_returns: torch.Tensor,\n",
    "    num_epochs: int,\n",
    "    minibatch_size: int,\n",
    "    clip_epsilon: float,\n",
    "    entropy_coef: float,\n",
    "    value_loss_coef: float,\n",
    "    max_grad_norm: float,\n",
    "    rng: np.random.Generator,\n",
    ") -> None:\n",
    "    \"\"\"Perform the PPO update step using collected batch data.\"\"\"\n",
    "    batch_size = batch_obs.size(0)\n",
    "    batch_advantages = (batch_advantages - batch_advantages.mean()) / (batch_advantages.std() + 1e-8)\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        indices = rng.permutation(batch_size)\n",
    "        for start in range(0, batch_size, minibatch_size):\n",
    "            end = start + minibatch_size\n",
    "            minibatch_indices = indices[start:end]\n",
    "\n",
    "            mb_obs = batch_obs[minibatch_indices]\n",
    "            mb_actions = batch_actions[minibatch_indices]\n",
    "            mb_log_probs_old = batch_log_probs_old[minibatch_indices]\n",
    "            mb_advantages = batch_advantages[minibatch_indices]\n",
    "            mb_returns = batch_returns[minibatch_indices]\n",
    "\n",
    "            mean, log_std, values_pred = model(mb_obs)\n",
    "            std = log_std.exp()\n",
    "            normal = torch.distributions.Normal(mean, std)\n",
    "\n",
    "            mb_actions_clamped = torch.clamp(mb_actions, -1.0 + EPSILON, 1.0 - EPSILON)\n",
    "            unsquashed_mb_actions = torch.atanh(mb_actions_clamped)\n",
    "            log_probs_gaussian = normal.log_prob(unsquashed_mb_actions).sum(dim=-1)\n",
    "            log_prob_squash_correction = torch.log(1.0 - mb_actions.pow(2) + EPSILON).sum(dim=-1)\n",
    "            log_probs_new = log_probs_gaussian - log_prob_squash_correction\n",
    "\n",
    "            entropy = normal.entropy().mean()\n",
    "            values_pred = values_pred.squeeze(-1)\n",
    "\n",
    "            prob_ratio = torch.exp(log_probs_new - mb_log_probs_old)\n",
    "            surr1 = prob_ratio * mb_advantages\n",
    "            surr2 = torch.clamp(prob_ratio, 1.0 - clip_epsilon, 1.0 + clip_epsilon) * mb_advantages\n",
    "            policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "            value_loss = 0.5 * ((values_pred - mb_returns) ** 2).mean()\n",
    "\n",
    "            loss = policy_loss + value_loss_coef * value_loss - entropy_coef * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Run the PPO training.\"\"\"\n",
    "    args = tyro.cli(Args)\n",
    "\n",
    "    # Ensure model directory exists\n",
    "    if not pathlib.Path.exists(pathlib.Path(args.model_dir)):\n",
    "        pathlib.Path.mkdir(pathlib.Path(args.model_dir))\n",
    "    print(\"Model directory:\", args.model_dir)\n",
    "\n",
    "    # Set the environment name based on the scenic file\n",
    "    env_name = pathlib.Path(args.scenic_file).stem\n",
    "\n",
    "    # Set up multiprocess start method\n",
    "    with contextlib.suppress(RuntimeError):\n",
    "        mp.set_start_method(\"spawn\")\n",
    "\n",
    "    # seeds\n",
    "    rng = np.random.default_rng(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    logger.info(\"Starting PPO training...\")\n",
    "    logger.info(\"Environment: %s, Workers: %s, Total Timesteps: %s\", env_name, args.num_workers, args.total_timesteps)\n",
    "    logger.info(\"Hyperparameters: gamma=%s, lambda=%s, clip_eps=%s, lr=%s\", args.gamma, args.gae_lambda, args.clip_epsilon, args.lr)\n",
    "\n",
    "    # temp env to get obs and action space\n",
    "    env = ScenicGymEnv(\n",
    "        env_name,\n",
    "        MetaDriveSimulator(timestep=0.05, sumo_map=pathlib.Path(\"../maps/Town06.net.xml\"), render=False, real_time=False),\n",
    "        observation_space=spaces.Box(low=-np.inf, high=np.inf, shape=(5, 7)),\n",
    "        action_space=spaces.Box(low=-1, high=1, shape=(2,)),\n",
    "        max_steps=700,\n",
    "    )\n",
    "    obs_space_shape = env.observation_space.shape\n",
    "    action_space = env.action_space\n",
    "    obs_dim = np.prod(obs_space_shape) if isinstance(obs_space_shape, tuple) else obs_space_shape[0]\n",
    "    env.close()\n",
    "\n",
    "    model = ActorCritic(obs_dim, action_space).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    batch_size = args.num_workers * args.steps_per_worker\n",
    "    num_updates = args.total_timesteps // batch_size\n",
    "    logger.info(\"Batch Size (Workers * Steps): %s\", batch_size)\n",
    "    logger.info(\"Total PPO Updates: %s\", num_updates)\n",
    "\n",
    "    data_queue = mp.Queue()\n",
    "\n",
    "    total_steps = 0\n",
    "    start_time = time.time()\n",
    "    episode_rewards = deque(maxlen=100)\n",
    "    episode_lengths = deque(maxlen=100)\n",
    "    total_episodes = 0\n",
    "\n",
    "    # Training Loop\n",
    "    for update in range(1, num_updates + 1):\n",
    "        update_start_time = time.time()\n",
    "        model.eval()\n",
    "\n",
    "        processes = []\n",
    "        current_model_state_dict = model.state_dict()\n",
    "        for i in range(args.num_workers):\n",
    "            p = mp.Process(\n",
    "                target=worker_fn,\n",
    "                args=(\n",
    "                    i,\n",
    "                    args.steps_per_worker,\n",
    "                    current_model_state_dict,\n",
    "                    data_queue,\n",
    "                    args.seed + update * args.num_workers,\n",
    "                    args.scenic_file,\n",
    "                ),\n",
    "            )\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "\n",
    "        all_trajectory_data = [data_queue.get() for _ in range(args.num_workers)]\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "        logger.debug(\"Update %s: All workers finished.\", update)\n",
    "\n",
    "        batch_obs_list = []\n",
    "        batch_actions_list = []\n",
    "        batch_log_probs_list = []\n",
    "        batch_advantages_list = []\n",
    "        batch_returns_list = []\n",
    "\n",
    "        for data in all_trajectory_data:\n",
    "            advantages, returns = compute_gae(\n",
    "                data[\"rewards\"],\n",
    "                data[\"values\"],\n",
    "                data[\"dones\"],\n",
    "                data[\"last_value\"],\n",
    "                data[\"last_done\"],\n",
    "                args.gamma,\n",
    "                args.gae_lambda,\n",
    "            )\n",
    "            batch_advantages_list.append(advantages)\n",
    "            batch_returns_list.append(returns)\n",
    "            batch_obs_list.append(data[\"observations\"])\n",
    "            batch_actions_list.append(data[\"actions\"])\n",
    "            batch_log_probs_list.append(data[\"log_probs\"])\n",
    "\n",
    "            current_episode_reward = 0\n",
    "            current_episode_length = 0\n",
    "            for reward, done in zip(data[\"rewards\"], data[\"dones\"], strict=False):\n",
    "                current_episode_reward += reward\n",
    "                current_episode_length += 1\n",
    "                if done:\n",
    "                    episode_rewards.append(current_episode_reward)\n",
    "                    episode_lengths.append(current_episode_length)\n",
    "                    total_episodes += 1\n",
    "                    current_episode_reward = 0\n",
    "                    current_episode_length = 0\n",
    "\n",
    "        batch_obs = torch.tensor(np.concatenate(batch_obs_list), dtype=torch.float32).to(device)\n",
    "        batch_actions = torch.tensor(np.concatenate(batch_actions_list), dtype=torch.float32).to(device)\n",
    "        batch_log_probs_old = torch.tensor(np.concatenate(batch_log_probs_list), dtype=torch.float32).to(device)\n",
    "        batch_advantages = torch.tensor(np.concatenate(batch_advantages_list), dtype=torch.float32).to(device)\n",
    "        batch_returns = torch.tensor(np.concatenate(batch_returns_list), dtype=torch.float32).to(device)\n",
    "\n",
    "        model.train()\n",
    "        ppo_update(\n",
    "            model,\n",
    "            optimizer,\n",
    "            batch_obs,\n",
    "            batch_actions,\n",
    "            batch_log_probs_old,\n",
    "            batch_advantages,\n",
    "            batch_returns,\n",
    "            args.num_epochs,\n",
    "            args.minibatch_size,\n",
    "            args.clip_epsilon,\n",
    "            args.entropy_coef,\n",
    "            args.value_loss_coef,\n",
    "            args.max_grad_norm,\n",
    "            rng,\n",
    "        )\n",
    "\n",
    "        total_steps += batch_size\n",
    "        update_end_time = time.time()\n",
    "        fps = int(batch_size / (update_end_time - update_start_time))\n",
    "        avg_reward = np.mean(episode_rewards) if episode_rewards else 0\n",
    "        avg_length = np.mean(episode_lengths) if episode_lengths else 0\n",
    "\n",
    "        if update % 1 == 0 or update == 1:\n",
    "            logger.info(\n",
    "                \"Update: %s/%s, Timesteps: %s/%s, FPS: %s, Episodes: %s, Avg Reward (Last 100): %.2f, Avg Length (Last 100): %.2f\",\n",
    "                update,\n",
    "                num_updates,\n",
    "                total_steps,\n",
    "                args.total_timesteps,\n",
    "                fps,\n",
    "                total_episodes,\n",
    "                avg_reward,\n",
    "                avg_length,\n",
    "            )\n",
    "            # Save model every 10 updates\n",
    "            torch.save(model.state_dict(), f\"{args.model_dir}/ppo_{env_name}_model.pth\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    logger.info(\"Training finished in %.2f seconds.\", end_time - start_time)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{args.model_dir}/ppo_{env_name}_model.pth\")\n",
    "    logger.info(\"Model saved to ppo_%s_model.pth\", env_name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a8049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af408e84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train(create_env, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03161f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796a7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_random_seed(0)\n",
    "# train_env=DummyVecEnv([partial(create_env, True) for _ in range(4)])\n",
    "# model = PPO(\"MlpPolicy\", \n",
    "#             train_env,\n",
    "#             n_steps=4096,\n",
    "#             verbose=1)\n",
    "\n",
    "# model.learn(total_timesteps=1000)\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fdeecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d74f2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "ACTION = {'agent0': [0.1, 0.5], 'agent1': [0.1, 0.5]}\n",
      "We done\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = dict(agent0 = [0.1, 0.5], agent1=[0.1, 0.5]) # First is throttle, second is steering\n",
    "for _ in range(2000):\n",
    "    o, r, te, tc, info = env.step(action)\n",
    "    if te or tc:\n",
    "        break\n",
    "        \n",
    "env.close()\n",
    "print(\"We done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
